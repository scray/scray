{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f463c4e3-b2c2-4a85-8604-51941e7908ed",
   "metadata": {},
   "source": [
    "# tool_update_encoded_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365c10db-5e6f-4cdb-9cca-8bdcce377ba2",
   "metadata": {},
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62276ad9-2063-4f6f-959b-519b94ce2817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dfBasics\n",
    "import common\n",
    "import encoder\n",
    "#import pfAdapt\n",
    "#import charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849076f-6695-4acc-b229-bd0787708cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e21252-87af-4f36-b046-f4bc77b7cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkSession = dfBasics.getSparkSession()\n",
    "#df = sparkSession.read.parquet('hdfs://172.30.17.145:8020/user/admin/sla/v00001/v00002/encoded/all/*/*').dropDuplicates() \n",
    "df  = sparkSession.read.parquet('/home/jovyan/work/output/v00003_v00000.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d4add-49db-4c6e-bf78-1a4004604198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde5b78f-499f-4ca9-b6ab-7cdad95b2634",
   "metadata": {},
   "source": [
    "## load encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3725aa-3292-4f54-9d40-0b4f5c3c684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dfBasics\n",
    "import pandas as pd\n",
    "\n",
    "version_sla = 'v00003'\n",
    "version     = version_sla + '/v00001'\n",
    "\n",
    "home_directory  =  '/home/jovyan/work/'\n",
    "share_directory =  '/home/jovyan/work/share/'\n",
    "#share_directory =  '/home/jovyan/share/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e2600-a036-433c-af38-a00b2620d19a",
   "metadata": {},
   "source": [
    "### init encoders (run only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c24828f-1851-48e0-ba21-a9fb2ba8f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - run this paragraph only once !\n",
    "# - if you get an 'allow_pickle' error you need Kernel/restart kernel\n",
    "\n",
    "import encoder\n",
    "import numpy as np\n",
    "\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "# restore np.load for future normal usage\n",
    "#np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad1cfa-8cf2-40c4-928e-47de6d0eb43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoders(columns):\n",
    "    npy= share_directory + 'sla/' + version_sla + '/npy'\n",
    "    encoders = {}\n",
    "    for column in columns:\n",
    "        _encoder = encoder.TolerantLabelEncoder(ignore_unknown=True)\n",
    "        #_encoder = TolerantLabelEncoder(ignore_unknown=True)\n",
    "        _encoder.classes_ = np.load(npy + '/' + column + '.npy')\n",
    "        encoders[column] = _encoder\n",
    "    return encoders    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248b464c-184b-41c0-8ae5-a1de5bb90c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['CSTATUS', 'CSERVICE', 'CSENDERENDPOINTID', 'CSENDERPROTOCOL','CRECEIVERPROTOCOL', 'CRECEIVERENDPOINTID']\n",
    "encoders = get_encoders(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5db5fe6-be00-43ce-b7e2-52f1d1332cdb",
   "metadata": {},
   "source": [
    "## functions_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9070e4cd-ce36-4aed-9c13-5f8bb8506672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import encoder\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036feef6-d769-45f2-b727-79477d95d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import time\n",
    "import datetime as dt\n",
    "import calendar\n",
    "import pytz\n",
    "de = pytz.timezone('Europe/Berlin')\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# long timestamp\n",
    "def date(x):\n",
    "    return  dt.datetime.fromtimestamp(float(x) / 1e3, tz=de)\n",
    "\n",
    "udf_add_year = udf(lambda z: date(z).date().year, IntegerType())\n",
    "udf_add_month = udf(lambda z: date(z).date().month, IntegerType())\n",
    "udf_add_day = udf(lambda z: date(z).date().day, IntegerType())\n",
    "udf_add_hour = udf(lambda z: date(z).time().hour, IntegerType())\n",
    "udf_add_minute = udf(lambda z: date(z).time().minute, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5964e1db-862b-44f1-9a55-12dd1a223cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "\n",
    "def transform(value):\n",
    "    if value == None:\n",
    "        value = 'None'\n",
    "    #result = int( _encoder.transform_version([value])[0])\n",
    "    result = int( _encoder.transform([value])[0])\n",
    "    return result\n",
    " \n",
    "    \n",
    "#udf_transform = udf(lambda z: transform(z), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f87ee7-36b9-47f2-8907-bbca72f832bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\"\"\"\n",
    "def transform(value,column=None, npy= share_directory + 'sla/' + version_sla + '/npy'):\n",
    "    if value == None:\n",
    "        value = 'None'\n",
    "    print(column,value)    \n",
    "    np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "    _encoder = encoder.TolerantLabelEncoder(ignore_unknown=True)\n",
    "    _encoder.classes_ = np.load(npy + '/' + column + '.npy')\n",
    "    return int( _encoder.transform([value])[0])\n",
    "\"\"\"\n",
    "#udf_transform = udf(lambda z: transform(z), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a76805-bdbd-4c17-b59b-9b6156ac85e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def check_transformed(value0,column,value):\n",
    "    if value0 == None or value == None:\n",
    "        return False\n",
    "    return value0 == transform(value,column=column)\n",
    "\n",
    "def calc_error(columns):\n",
    "    status = columns[0]\n",
    "    service = columns[1]\n",
    "    error=int(not( ( check_transformed(status,'CSTATUS','PENDING') & check_transformed(service,'CSERVICE','InvoicePortal')  ) | \\\n",
    "        (check_transformed(status,'CSTATUS','PENDING') & check_transformed(service,'CSERVICE','IDS')  ) | \\\n",
    "        check_transformed(status,'CSTATUS','SUCCESS') | \\\n",
    "        check_transformed(status,'CSTATUS','SUCCESS_DOWNLOADED') | check_transformed(status,'CSTATUS','SUCCESS_POLLQUEUE')  ))\n",
    "    return error\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93fccc3-8112-4ea6-83d4-a04e3faba8f7",
   "metadata": {},
   "source": [
    "### encode value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d9be1-6038-43b4-b25c-829522b0f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def etransform(value,column=None, npy= share_directory + 'sla/' + version_sla + '/npy'):\n",
    "    np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "    _encoder = encoder.TolerantLabelEncoder(ignore_unknown=True)\n",
    "    _encoder.classes_ = np.load(npy + '/' + column + '.npy')\n",
    "    return int( _encoder.transform([value])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e661cf8-7bad-4d2e-b52f-a39ccf04450f",
   "metadata": {},
   "source": [
    "### decode value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a674f9c7-2a33-4db4-a8c0-7be528937d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(value,column=None, npy= share_directory + 'sla/' + version_sla + '/npy'):\n",
    "    _encoder = encoder.TolerantLabelEncoder(ignore_unknown=True)\n",
    "    _encoder.classes_ = np.load(npy + '/' + column + '.npy')\n",
    "    if type(value) == int:\n",
    "        return str(_encoder.inverse_transform(value))  \n",
    "    elif type(value) == list:\n",
    "        return [str(_encoder.inverse_transform(v)) for v in value]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39331ba4-f66f-4221-b7e7-336a7408b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_transformed(value0,column,value):\n",
    "    return value0 == etransform(value,column=column)\n",
    "\n",
    "def calc_error(columns):\n",
    "    status = columns[0]\n",
    "    service = columns[1]\n",
    "    error=int(not( ( check_transformed(status,'CSTATUS','PENDING') & check_transformed(service,'CSERVICE','InvoicePortal')  ) | \\\n",
    "        (check_transformed(status,'CSTATUS','PENDING') & check_transformed(service,'CSERVICE','IDS')  ) | \\\n",
    "        check_transformed(status,'CSTATUS','SUCCESS') | \\\n",
    "        check_transformed(status,'CSTATUS','SUCCESS_DOWNLOADED') | check_transformed(status,'CSTATUS','SUCCESS_POLLQUEUE')  ))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447ae920-2363-4e45-84ab-e5fa3c4f0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "udf_add_error = udf(lambda y,z: calc_error((y,z)), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e809619a-0a80-4311-b6b0-692cc886ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_columns_spark(dataframe=None,columns=None, encoders=None):\n",
    "    for column in columns:\n",
    "        #print(column)\n",
    "        global _encoder\n",
    "        _encoder = encoders[column]\n",
    "        #print(column,_encoder)\n",
    "        udf_transform = udf(lambda z: transform(z), StringType())\n",
    "        dataframe=dataframe.withColumn(column, udf_transform(col(column)).cast(\"Integer\"))\n",
    "        #print(dataframe.head())\n",
    "    return dataframe\n",
    "\n",
    "def cast_spark_columns(dataframe=None,columns=[],type=\"int\" ):\n",
    "    for column in columns:\n",
    "        dataframe = dataframe.withColumn(column, col(column).cast(type))\n",
    "    return dataframe    \n",
    "\n",
    "def process(dataframe=None, encoders=None, columns=None, sender=None):\n",
    "    df3 = encode_columns_spark(dataframe=dataframe,columns=columns, encoders=encoders)\n",
    "    #df3 = df3.withColumn(\"year\", udf_add_year(df3.CSTARTTIME)).withColumn(\"month\", udf_add_month(df3.CSTARTTIME)).withColumn(\"day\", udf_add_day(df3.CSTARTTIME)).withColumn(\"hour\", udf_add_hour(df3.CSTARTTIME)).withColumn(\"minute\", udf_add_minute(df3.CSTARTTIME)) \n",
    "    df3=cast_spark_columns(dataframe=df3, columns=['CSTARTTIME', 'CENDTIME','CINBOUNDSIZE','CSLATAT','CMESSAGETAT2','CSLADELIVERYTIME'], type='long')\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d96231-049e-4650-8650-0074e1a231d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_encoder.transform_version(['None'])\n",
    "#_encoder.transform([None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4b2d7-f021-486d-b7c9-f9e2d90c01b1",
   "metadata": {},
   "source": [
    "## update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32d746-017b-4141-97b6-6b3b475bea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_update(year,month,week,df,encoders=None, columns=None):\n",
    "    df2 = df.where(f.col(\"year\").isin([year])).where(f.col(\"week\").isin([week]))\n",
    "    df3 = process(dataframe=df2, encoders=encoders, columns=columns)\n",
    "    df4 = df3.withColumn(\"error\", udf_add_error(f.col(\"CSTATUS\"), f.col(\"CSERVICE\")).cast(IntegerType()))\n",
    "    df4.write.mode('overwrite').parquet('/home/jovyan/work/output/v00003_v00001/sla_enc_v00003_v00001_' + str(year) + '_' + str(month) + '_' + str(week) + '.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a547a1-8c62-4a78-bc54-acc4f5250498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir /home/jovyan/work/output/v00003_v00000\n",
    "#!ls /home/jovyan/work/output/v00003_v00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f36b8-94fe-4783-bfb1-4f736b2e356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ear = 2019\n",
    "month = 10\n",
    "df2 = df.where(f.col(\"year\").isin([year])).where(f.col(\"month\").isin([month]))\n",
    "    \n",
    "df3 = df2.where((f.col('CSTATUS')==-1) | (f.col('CSERVICE')==-1) | (f.col('CSENDERENDPOINTID')==-1) | (f.col('CSENDERPROTOCOL')==-1)| (f.col('CRECEIVERPROTOCOL')==-1) | (f.col('CRECEIVERENDPOINTID')==-1))\n",
    "ids = np.array(df3.select('CGLOBALMESSAGEID').drop_duplicates().collect())     \n",
    "ids = [i[0] for i in ids.tolist()]\n",
    "not_ids = np.array(df2.select('CGLOBALMESSAGEID').filter(df2.CGLOBALMESSAGEID.isin(ids) == False).drop_duplicates().collect())  \n",
    "not_ids = [i[0] for i in not_ids.tolist()]\n",
    "\n",
    "df_update_1 = df_org.where(f.col(\"CGLOBALMESSAGEID\").isin(ids))\n",
    "df_update_2 = process(dataframe=df_update_1, encoders=encoders, columns=columns)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b9d54-4973-4d9b-8a95-659fce1c2a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_df3 = encode_columns_spark(dataframe=df_update_1,columns=columns, encoders=encoders)\n",
    "#_df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e92a8e-169f-491d-a18f-29932815ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_update_2 = process(dataframe=df_update_1, encoders=encoders, columns=columns)\n",
    "#df_update_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70e725-12b1-4aa9-a400-e404d55cacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#date(z).date().year\n",
    "#df2 = df.where(f.col(\"CSTARTTIME\").isin([year]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39461e6-2b30-4d1c-8cb0-54e4b3af9ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "year = 2019\n",
    "month = 11\n",
    "#process_update(year,month,df,encoders=encoders, columns=columns) \n",
    "\n",
    "\n",
    "df2 = df.where(f.col(\"year\").isin([year])).where(f.col(\"month\").isin([month]))\n",
    "df3 = process(dataframe=df2, encoders=encoders, columns=columns)\n",
    "df4 = df3.withColumn(\"error\", udf_add_error(f.col(\"CSTATUS\"), f.col(\"CSERVICE\")).cast(IntegerType()))\n",
    "#df4.write.mode('overwrite').parquet('/home/jovyan/work/output/v00003_v00001/sla_enc_v00003_v00001_' + str(year) + '_' + str(month) + '.parquet')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813402ab-02ba-40f8-b93a-238047a7fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df4.limit(1).toPandas()\n",
    "#df3.limit(1).toPandas()\n",
    "#encoders,columns\n",
    "#_df3 = encode_columns_spark(dataframe=df2,columns=columns, encoders=encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b1a033-7ae7-4635-bd4c-ba692e052718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_df3.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705c7783-c0d5-4a9e-880a-8e031b4464fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_weeks(df):\n",
    "    columns = ['year','month','week']\n",
    "    return df.select(columns).dropDuplicates().toPandas() \n",
    "\n",
    "def get_weeks(pf,year):\n",
    "    l =  list(pf[pf['year'] == year]['week'])\n",
    "    l.sort()\n",
    "    return l\n",
    "\n",
    "pf_year_weeks = get_year_weeks(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442980b6-09d3-4775-97d1-efab8a5d2edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df2 = df.where(f.col(\"year\").isin([2023])).where(f.col(\"week\").isin([52]))\n",
    "pdf2 = df2.toPandas()\n",
    "pdf2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c1b1bf-f551-4843-80e5-4269ddfc3ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2019,2020,2021,2022,2023]\n",
    "for year in years:\n",
    "    weeks = get_weeks(pf_year_weeks,year)\n",
    "    for week in weeks:\n",
    "        month = pf_year_weeks[(pf_year_weeks['year'] == year) & (pf_year_weeks['week'] == week)].iloc[0]['month']\n",
    "        process_update(year,month,week,df,encoders=encoders, columns=columns)           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
