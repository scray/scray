{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo: loads file with all messages (CSTARTTIME, CSENDERENDPOINTID, ymdhm )\n",
    "# show some charts, anomaly detection with LSTM autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base.dfBasics as dfBasics\n",
    "import base.common as common\n",
    "import base.encoder as encoder\n",
    "import base.pfAdapt as pfAdapt\n",
    "import base.charts as charts\n",
    "#import base.anomaly as anomaly\n",
    "\n",
    "import pandas as pd    \n",
    "from pyspark.sql import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/11/16 14:56:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/11/16 14:56:16 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "22/11/16 14:56:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/11/16 14:56:17 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "sparkSession = dfBasics.getSparkSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "def listdirectory(path=None,filter='.'):\n",
    "    return [x for x in listdir(path) if not x.startswith(filter)]    \n",
    "\n",
    "_files = listdirectory(path='/tmp/enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sla_enc_772e6440-e973-11e8-be62-528eac1b495c.parquet',\n",
       " '772e6440-e973-11e8-be62-528eac1b495c')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_files)\n",
    "_files[0], senders[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## senders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senders = sparkSession.read.parquet(\"/tmp/senders.parquet\")\n",
    "senders = list(senders.toPandas()['CSENDERENDPOINTID'])\n",
    "#len(senders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "senders = list(sparkSession.read.parquet('hdfs://172.30.17.145:8020/tmp/data/senders.parquet').toPandas()['CSENDERENDPOINTID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sf = pd.read_csv('/tmp/directory_sizes.txt', delimiter = \"\\t\")\n",
    "sf.columns =['size','file']\n",
    "sf.drop(sf.tail(1).index,inplace=True) # drop last n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = sf.sort_values(['size'])\n",
    "sf.iloc[len(sf)-1].file\n",
    "#sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = sparkSession.read.parquet('hdfs://172.30.17.145:8020/tmp/data/enc/' + 'sla_enc_' + senders[0] + '.parquet')\n",
    "pfall = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sparkSession.read.parquet('/tmp/' + sf.iloc[len(sf)-1].file)\n",
    "pfall = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sparkSession.read.parquet('/tmp/enc/' + _files[1])\n",
    "pfall = df.toPandas() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in _files:\n",
    "    try:\n",
    "        print(file)\n",
    "        df = sparkSession.read.parquet('/tmp/enc/' + file)\n",
    "        pfall = df.toPandas() \n",
    "    except Exception as exception:    \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senders=senders[19:]\n",
    "len(senders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1579760627614 - 1579760619146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df = sparkSession.read.parquet('hdfs://172.30.17.145:8020/user/admin/sla/CSENDERENDPOINTID/CSENDERENDPOINTID_9.parquet')\n",
    "#df = sparkSession.read.parquet('hdfs://172.30.17.145:8020/user/admin/sla/sla_1580137124017.parquet')\n",
    "#df = sparkSession.read.parquet('hdfs://172.30.17.145:8020/user/admin/sla/sla_1616754087742.parquet')\n",
    "#df = sparkSession.read.parquet('hdfs://172.30.17.145:8020/user/admin/CSENDERENDPOINTID/CSENDERENDPOINTID_2191.parquet')\n",
    "df = sparkSession.read.parquet('hdfs://172.30.17.145:8020/user/admin/CSENDERENDPOINTID_full/CSENDERENDPOINTID_9.parquet')\n",
    "pfall = df.toPandas() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSENDERENDPOINTID=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "SparkSession.builder.config('spark.local.dir', '/tmp').config(\"spark.executor.memory\", \"8g\").config(\"spark.driver.memory\", \"8g\").config(\"spark.driver.maxResultSize\", \"0\").appName(\"jupyter\").master(\"spark://clspromon-aio01.txx.seeburger.de:7077\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "sparkSession = SparkSession.builder.config('spark.local.dir', '/tmp').config(\"spark.executor.memory\", \"8g\").config(\"spark.driver.memory\", \"8g\").config(\"spark.driver.maxResultSize\", \"0\").appName(\"jupyter\").master(\"spark://clspromon-aio01.txx.seeburger.de:7077\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkSession.getActiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup charts\n",
    "import pandas as pd\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "print(\"Setup Complete\")\n",
    "\n",
    "def get_ym_string(a,b) :\n",
    "    return a + \"-\" + b\n",
    "    #return a.join([\"-\",b]) \n",
    "\n",
    "def get_ym(mdcountsall) :\n",
    "    a = mdcountsall.index.get_level_values(0).astype(str)\n",
    "    b = mdcountsall.index.get_level_values(1).astype(str)\n",
    "    return a,b\n",
    "\n",
    "def get_ymd(mdcountsall) :\n",
    "    a = mdcountsall.index.get_level_values(0).astype(str)\n",
    "    b = mdcountsall.index.get_level_values(1).astype(str)\n",
    "    c = mdcountsall.index.get_level_values(2).astype(str)\n",
    "    return a,b,c\n",
    "\n",
    "def make_2digits(blist):\n",
    "    for n, b in enumerate(blist):\n",
    "        if int(b) < 10:\n",
    "             blist[n] = '0' + str(b)\n",
    "    return blist\n",
    "\n",
    "def get_ymd_string(a,b,c) :\n",
    "    if isinstance(a, str) :\n",
    "        return a + \"-\" + make_2digits([b])[0] + \"-\" + make_2digits([c])[0] \n",
    "    elif isinstance(a,pd.core.series.Series):\n",
    "        return a.astype(str) + \"-\" + make_2digits(b.astype(str)) + \"-\" + make_2digits(c.astype(str))\n",
    "    return a + \"-\" + pd.Index(make_2digits(b.tolist())) + \"-\" + pd.Index(make_2digits(c.tolist())) \n",
    "\n",
    "def get_ymdh(mdcountsall) :\n",
    "    a = mdcountsall.index.get_level_values(0).astype(str)\n",
    "    b = mdcountsall.index.get_level_values(1).astype(str)\n",
    "    c = mdcountsall.index.get_level_values(2).astype(str)\n",
    "    d = mdcountsall.index.get_level_values(3).astype(str)\n",
    "    return a,b,c,d\n",
    "\n",
    "def get_ymdhm(mdcountsall) :\n",
    "    a = mdcountsall.index.get_level_values(0).astype(str)\n",
    "    b = mdcountsall.index.get_level_values(1).astype(str)\n",
    "    c = mdcountsall.index.get_level_values(2).astype(str)\n",
    "    d = mdcountsall.index.get_level_values(3).astype(str)\n",
    "    e = mdcountsall.index.get_level_values(4).astype(str)\n",
    "    return a,b,c,d,e\n",
    "\n",
    "def get_ymdh_string(a,b,c,d) :\n",
    "    if isinstance(a, str) :\n",
    "        return a + \"-\" + make_2digits([b])[0] + \"-\" + make_2digits([c])[0] + \"-\" + make_2digits([d])[0]\n",
    "    elif isinstance(a,pd.core.series.Series):\n",
    "        return a.astype(str) + \"-\" + make_2digits(b.astype(str)) + \"-\" + make_2digits(c.astype(str)) + \"-\" + make_2digits(d.astype(str))\n",
    "    return a + \"-\" + pd.Index(make_2digits(b.tolist())) + \"-\" + pd.Index(make_2digits(c.tolist())) + \"-\" + pd.Index(make_2digits(d.tolist()))\n",
    "\n",
    "def get_ymdhm_string(a,b,c,d,e) :\n",
    "    if isinstance(a, str) :\n",
    "        return a + \"-\" + make_2digits([b])[0] + \"-\" + make_2digits([c])[0] + \"-\" + make_2digits([d])[0] + \"-\" + make_2digits([e])[0]\n",
    "    elif isinstance(a,pd.core.series.Series):\n",
    "        return a.astype(str) + \"-\" + make_2digits(b.astype(str)) + \"-\" + make_2digits(c.astype(str)) + \"-\" + make_2digits(d.astype(str)) + \"-\" + make_2digits(e.astype(str))\n",
    "    return a + \"-\" + pd.Index(make_2digits(b.tolist())) + \"-\" + pd.Index(make_2digits(c.tolist())) + \"-\" + pd.Index(make_2digits(d.tolist())) + \"-\" + pd.Index(make_2digits(e.tolist()))\n",
    "\n",
    "\n",
    "def createData_ym(pfall,month) :\n",
    "    if (month > 0) & (month < 13) :\n",
    "        mdcountsall = pfall[(pfall['month'] == month)].groupby(['year','month'])['year'].count()\n",
    "    else :\n",
    "        mdcountsall = pfall.groupby(['year','month'])['year'].count()    \n",
    "    a,b = get_ym(mdcountsall)\n",
    "    data2 = pd.DataFrame()\n",
    "    data2['date'] = get_ym_string(a,b)\n",
    "    data2['outcome'] = mdcountsall.reset_index(level=0, drop=True).reset_index()['year'].astype(int) \n",
    "    return data2\n",
    "\n",
    "def createData(pfall,month=-1,year=2020,outcome='outcome') :\n",
    "    if (month > 0) & (month < 13) :\n",
    "        mdcountsall = pfall[(pfall['year'] == year) & (pfall['month'] == month)].groupby(['year','month','day','hour'])['year'].count()\n",
    "    else :\n",
    "        mdcountsall = pfall.groupby(['year','month','day','hour'])['year'].count()    \n",
    "    a,b,c,d = get_ymdh(mdcountsall)\n",
    "    data2 = pd.DataFrame()\n",
    "    data2['date'] = get_ymdh_string(a,b,c,d)\n",
    "    data2[outcome] =  mdcountsall.reset_index(level=0, drop=True).reset_index()['year'].astype(int)\n",
    "\n",
    "    #for pivot table\n",
    "    data2['hours'] =  d.astype(int) \n",
    "    data2['days']  =  c.astype(int) \n",
    "    return data2\n",
    "\n",
    "\n",
    "def createData_ymd(pfall,month,year=2020) :\n",
    "    if (month > 0) & (month < 13) :\n",
    "        mdcountsall = pfall[(pfall['year'] == year) & (pfall['month'] == month)].groupby(['year','month','day'])['year'].count()\n",
    "    else :\n",
    "        mdcountsall = pfall.groupby(['year','month','day'])['year'].count()    \n",
    "    a,b,c = get_ymd(mdcountsall)\n",
    "    data2 = pd.DataFrame()\n",
    "    data2['date'] = get_ymd_string(a,b,c)\n",
    "    data2['year'] = a.astype(int) \n",
    "    data2['month'] = b.astype(int) \n",
    "    data2['day'] = c.astype(int) \n",
    "    data2['outcome'] = mdcountsall.reset_index(level=0, drop=True).reset_index()['year'].astype(int) \n",
    "    return data2\n",
    "\n",
    "def createData_ymdh(pfall,month,year=2020) :\n",
    "    if (month > 0) & (month < 13) :\n",
    "        mdcountsall = pfall[(pfall['year'] == year) & (pfall['month'] == month)].groupby(['year','month','day','hour'])['year'].count()\n",
    "    else :\n",
    "        mdcountsall = pfall.groupby(['year','month','day','hour'])['year'].count()    \n",
    "    a,b,c,d = get_ymdh(mdcountsall)\n",
    "    data2 = pd.DataFrame()\n",
    "    data2['date'] = get_ymdh_string(a,b,c,d)\n",
    "    data2['year'] = a.astype(int) \n",
    "    data2['month'] = b.astype(int) \n",
    "    data2['day'] = c.astype(int) \n",
    "    data2['hour'] = d.astype(int)\n",
    "    data2['outcome'] = mdcountsall.reset_index(level=0, drop=True).reset_index()['year'].astype(int) \n",
    "    return data2\n",
    "\n",
    "def createData_ymdhm(pfall,month,year=2020) :\n",
    "    if (month > 0) & (month < 13) :\n",
    "        mdcountsall = pfall[(pfall['year'] == year) & (pfall['month'] == month)].groupby(['year','month','day','hour','minute'])['year'].count()\n",
    "    else :\n",
    "        mdcountsall = pfall.groupby(['year','month','day','hour','minute'])['year'].count()    \n",
    "    a,b,c,d,e = get_ymdhm(mdcountsall)\n",
    "    data2 = pd.DataFrame()\n",
    "    data2['date'] = get_ymdh_string(a,b,c,d)\n",
    "    data2['year'] = a.astype(int) \n",
    "    data2['month'] = b.astype(int) \n",
    "    data2['day'] = c.astype(int) \n",
    "    data2['hour'] = d.astype(int)\n",
    "    data2['minute'] = e.astype(int)\n",
    "    data2['outcome'] = mdcountsall.reset_index(level=0, drop=True).reset_index()['year'].astype(int) \n",
    "    return data2\n",
    "\n",
    "\n",
    "def createData_column_ymdh(pfall,month=-1,year=2020, column=None) :\n",
    "    if (month > 0) & (month < 13) :\n",
    "        mdcountsall = pfall[(pfall['year'] == year) & (pfall['month'] == month)]\n",
    "    else :\n",
    "        mdcountsall = pfall \n",
    "    #a,b,c,d = get_ymdh(mdcountsall)\n",
    "    data2 = pd.DataFrame()\n",
    "    data2['date'] = get_ymdh_string(pfall['year'], pfall['month'], pfall['day'],pfall['hour'])\n",
    "    df2 = mdcountsall[['year', 'month', 'day','hour',column]].copy()\n",
    "    data2 = pd.concat([data2, df2], axis=1)\n",
    "    data2.columns = list(data2.columns[:-1]) + ['outcome']\n",
    "    \n",
    "    return data2\n",
    "\n",
    "\n",
    "def createData_column_ymd(pfall,month=-1,year=2020, column=None) :\n",
    "    if (month > 0) & (month < 13) :\n",
    "        mdcountsall = pfall[(pfall['year'] == year) & (pfall['month'] == month)]\n",
    "    else :\n",
    "        mdcountsall = pfall \n",
    "    #a,b,c,d = get_ymdh(mdcountsall)\n",
    "    data2 = pd.DataFrame()\n",
    "    data2['date'] = get_ymd_string(pfall['year'], pfall['month'], pfall['day'])\n",
    "    df2 = mdcountsall[['year', 'month', 'day',column]].copy()\n",
    "    data2 = pd.concat([data2, df2], axis=1)\n",
    "    data2.columns = list(data2.columns[:-1]) + ['outcome']\n",
    "    \n",
    "    return data2\n",
    "\n",
    "\n",
    "def label(graph,skip,rot) :\n",
    "    for ind, label in enumerate(graph.get_xticklabels()):\n",
    "        if ind % skip == 0:  # every 10th label is kept\n",
    "            label.set_visible(True)\n",
    "            label.set_rotation(rot)\n",
    "        else:\n",
    "            label.set_visible(False)\n",
    "\n",
    "def createBarplot(md=None,fx=24,fy=12,fontscale=3.0,title=\"\") :\n",
    "    sns.set(style='whitegrid', palette='muted', font_scale=fontscale)\n",
    "    plt.figure(figsize=(fx,fy))\n",
    "    plt.title(title)\n",
    "    ax = sns.barplot(x=md['date'], y=md['outcome'], data=md)\n",
    "    plt.setp( ax.xaxis.get_majorticklabels(), rotation=75 )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return ax\n",
    "\n",
    "## heatmap\n",
    "def createHeatmap(piv,title=\"\") :\n",
    "    plt.figure(figsize=(24,8))\n",
    "    plt.title(title)\n",
    "    ax = sns.heatmap(piv, square=True)\n",
    "    plt.setp( ax.xaxis.get_majorticklabels(), rotation=0 )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pfall\n",
    "#pfall5 = createData_column_ymdh(pfall,column='CMESSAGETAT2')\n",
    "#get_ymdh_string(pfall5['year'], pfall5['month'], pfall5['day'],pfall5['hour'])\n",
    "#pfall5['year']\n",
    "#pfall5['year'].astype(str) + '_' + make_2digits(pfall5['month'].astype(str))\n",
    "#make_2digits([c])[0] \n",
    "\n",
    "#pfall5.columns = pfall5.columns[:-1] + 'outcome'\n",
    "#pfall5.columns = list(pfall5.columns[:-1]) + ['outcome']\n",
    "#pfall5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year=2022\n",
    "#month=7\n",
    "#mdcountsall = pfall[(pfall['year'] == year) & (pfall['month'] == month)].groupby(['year','month','day','hour'])['year'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checka(pfall[(pfall[year]== 2022) & (pfall[month]== 7)])\n",
    "#pfall[(pfall[year]== '2022') & (pfall[month]== '7')]\n",
    "#pfall[(pfall[year] == 2022)] \n",
    "#pfall\n",
    "#pfall5 = createData_column_ymdh(pfall,column='CMESSAGETAT2')\n",
    "#pfall6 = checka(pfall5)\n",
    "#pd.unique(pfall5['year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calendar import monthrange\n",
    "\n",
    "def get_month(pda, year=2020, month=1):\n",
    "    return pda[(pda['month'] == month) & (pda['year'] == year)]\n",
    "\n",
    "def is_complete(pda, year=2020, month=1):\n",
    "    mm = pda[(pda['month'] == month) & (pda['year'] == year)]\n",
    "    if len(mm) > 0:\n",
    "        return monthrange(year, month)[1] == len(mm)\n",
    "    return None\n",
    "    \n",
    "def check_complete(pda, year=2020):\n",
    "    for m in range(1, 13):\n",
    "        mm = pda[(pda['month'] == m) & (pda['year'] == year)]\n",
    "        if len(mm) > 0:\n",
    "            print(m,monthrange(year, m)[1] == len(mm))\n",
    "\n",
    "            \n",
    "def add_line_to_dataframe(df=None,year=None,month=None,day=None,hour=None,minute=None,value=0): \n",
    "    \n",
    "    if hour is not None:\n",
    "        if minute is not None:\n",
    "            _date = get_ymdhm_string(str(year),str(month),str(day),str(hour),str(minute)) \n",
    "            df.loc[len(df)]=[_date,year,month,day,hour,minute,value]  \n",
    "        else:    \n",
    "            _date = get_ymdh_string(str(year),str(month),str(day),str(hour)) \n",
    "            df.loc[len(df)]=[_date,year,month,day,hour,value]   \n",
    "    else:    \n",
    "        _date = get_ymd_string(str(year),str(month),str(day))\n",
    "        df.loc[len(df)]=[_date,year,month,day,value]     \n",
    "    \n",
    "def check_and_fill_hours_of_day(df=None,year=2022,month=7,day=None):\n",
    "    _df=df[(df['year']==year) & (df['month']==month) & (df['day']==day)] \n",
    "    #print(_df)\n",
    "    \n",
    "    minutes = False\n",
    "    if 'minute' in df.columns:\n",
    "        minutes = True\n",
    "    \n",
    "    for hour in range(0, 24):\n",
    "        if len(_df[_df['hour']==hour]) == 0:\n",
    "            if minutes == True:\n",
    "                for minute in range(0, 59):\n",
    "                    #_date = get_ymdhm_string(str(year),str(month),str(day),str(hour),str(minute))  \n",
    "                    add_line_to_dataframe(df=df,year=year,month=month,day=day,hour=hour,minute=minute) \n",
    "            else:\n",
    "                #_date = get_ymdh_string(str(year),str(month),str(day),str(hour))  \n",
    "                add_line_to_dataframe(df=df,year=year,month=month,day=day,hour=hour) \n",
    "        else:\n",
    "            if minutes == True:\n",
    "                _df2 = _df[_df['hour']==hour]\n",
    "                for minute in range(0, 59):\n",
    "                    if len(_df2[_df2['minute']==minute]) == 0:\n",
    "                        add_line_to_dataframe(df=df,year=year,month=month,day=day,hour=hour,minute=minute)\n",
    "            else:\n",
    "                pass\n",
    "    #print (df)        \n",
    "    return df     \n",
    "    \n",
    "    \n",
    "#pda :  date,year,month,day.outcome \n",
    "def fill(pda,year,month,min_day=1,max_day=-1,hours=False): \n",
    "    if max_day == -1:\n",
    "        days = monthrange(year, month)[1]\n",
    "    else:\n",
    "        days = max_day\n",
    "        \n",
    "    #print(min_day,days,max_day,hours)     \n",
    "    minutes = False\n",
    "    if 'minute' in pda.columns:\n",
    "        minutes = True\n",
    "        \n",
    "    df = pda[(pda['month'] == month) & (pda['year'] == year)]\n",
    "    for day in range(min_day, days + 1):\n",
    "        if len(df[df['day']==day]) == 0:\n",
    "            #print(day)\n",
    "            if hours == True:\n",
    "                for hour in range (0,24):\n",
    "                    if minutes == True:\n",
    "                        for minute in range(0, 59): \n",
    "                            add_line_to_dataframe(df=pda,year=year,month=month,day=day,hour=hour,minute=minute) \n",
    "                    else:\n",
    "                        add_line_to_dataframe(df=pda,year=year,month=month,day=day,hour=hour) \n",
    "            else:    \n",
    "                add_line_to_dataframe(df=pda,year=year,month=month,day=day)\n",
    "        else:\n",
    "            if hours == True:\n",
    "                #print(year,month,day)\n",
    "                check_and_fill_hours_of_day(df=pda,year=year,month=month,day=day)\n",
    "       \n",
    "    \n",
    "def check(pda):\n",
    "    _start_year = min(pd.unique(pda['year']))\n",
    "    _end_year = max(pd.unique(pda['year']))  \n",
    "    _start_month = min(pd.unique(pda[pda['year']== _start_year]['month']))\n",
    "    _end_month = max(pd.unique(pda[pda['year']== _end_year]['month']))\n",
    "    _end = 13\n",
    "    \n",
    "    if 'hour' in pda.columns:\n",
    "        hours = True\n",
    "    else:\n",
    "        hours = False\n",
    "        \n",
    "    for year in range(_start_year,_end_year+1):   \n",
    "        for month in range(_start_month,_end):        \n",
    "            #print(year,month, _end_month, _end_year)\n",
    "            \n",
    "            if((month == _start_month) & (year == _start_year)):\n",
    "                min_day = (min(list(pda[(pda['month'] == month) & (pda['year'] == year)]['day'])))\n",
    "            else:\n",
    "                min_day = 1\n",
    "                \n",
    "            if((month == _end_month) & (year == _end_year)):\n",
    "                max_day = (max(list(pda[(pda['month'] == month) & (pda['year'] == year)]['day'])))\n",
    "                #print(month,year,max_day)\n",
    "                fill(pda,year,month,min_day=min_day, max_day=max_day,hours=hours)\n",
    "            else:    \n",
    "                fill(pda,year,month,min_day=min_day,hours=hours)\n",
    "            if (year == _end_year) &  (month == _end_month):\n",
    "                #print('DONE')\n",
    "                break    \n",
    "        _start_month=1\n",
    "            \n",
    "        if year == (_end_year-1):\n",
    "            _end = _end_month + 1     \n",
    "            \n",
    "        if (year == _end_year) &  (month == _end_month):\n",
    "            #print('DONE')\n",
    "            break       \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019-10-29-00\n",
    "# 2022-10-06-23\n",
    "\n",
    "def mean_column(column):\n",
    "    return int(round(column.mean(),0))\n",
    "\n",
    "def check_and_fill_hours_of_daya(df=None,year=2022,month=7,day=None, outcome='outcome'):\n",
    "    _df=df[(df['year']==year) & (df['month']==month) & (df['day']==day)] \n",
    "    \n",
    "    df=pd.DataFrame(columns=['date', 'year', 'month', 'day', 'hour', outcome])\n",
    "    for hour in range(0, 24):\n",
    "        _hours = _df[_df['hour']==hour]\n",
    "        if len(_df[_df['hour']==hour]) == 0:\n",
    "            _date = get_ymdh_string(str(year),str(month),str(day),str(hour))  \n",
    "            add_line_to_dataframe(df=df,year=year,month=month,day=day,hour=hour) \n",
    "            pass\n",
    "        else:\n",
    "            add_line_to_dataframe(df=df,year=year,month=month,day=day,hour=hour,value=mean_column(_hours[outcome]))\n",
    "    #print (df)      \n",
    "    return df \n",
    "\n",
    "#pda :  date,year,month,day.outcome \n",
    "def filla(pda,year,month,min_day=1,max_day=-1,hours=False, outcome='outcome'): \n",
    "    if max_day == -1:\n",
    "        days = monthrange(year, month)[1]\n",
    "    else:\n",
    "        days = max_day\n",
    "        \n",
    "    #df = pda[(pda['month'] == month) & (pda['year'] == year)]\n",
    "    if hours == True:\n",
    "        df=pd.DataFrame(columns=['date', 'year', 'month', 'day', 'hour', outcome])\n",
    "    else:\n",
    "        df=pd.DataFrame(columns=['date', 'year', 'month', 'day', outcome])\n",
    "        \n",
    "    for day in range(min_day, days + 1):\n",
    "        if hours == True:\n",
    "            df_b = check_and_fill_hours_of_daya(df=pda,year=year,month=month,day=day,outcome=outcome)\n",
    "            df = pd.concat([df, df_b], ignore_index=True)   \n",
    "        else:\n",
    "            _df=pda[(pda['year']==year) & (pda['month']==month) & (pda['day']==day)]\n",
    "            if len(_df) > 0 :\n",
    "                #print(len(_df),mean_column(_df['outcome']), list(_df['outcome']))\n",
    "                value=mean_column(_df[outcome])\n",
    "            else:\n",
    "                value=0\n",
    "            add_line_to_dataframe(df=df,year=year,month=month,day=day,value=value) \n",
    "    return df   \n",
    "            \n",
    "    \n",
    "def checka(pda, outcome='outcome'):\n",
    "    _start_year = min(pd.unique(pda['year']))\n",
    "    _end_year = max(pd.unique(pda['year']))  \n",
    "    _start_month = min(pd.unique(pda[pda['year']== _start_year]['month']))\n",
    "    _end_month = max(pd.unique(pda[pda['year']== _end_year]['month']))\n",
    "    _end = 13\n",
    "    \n",
    "    if 'hour' in pda.columns:\n",
    "        hours = True\n",
    "        df=pd.DataFrame(columns=['date', 'year', 'month', 'day', 'hour', outcome])\n",
    "    else:\n",
    "        hours = False\n",
    "        df=pd.DataFrame(columns=['date', 'year', 'month', 'day', outcome])\n",
    "    \n",
    "    \n",
    "    for year in range(_start_year,_end_year+1):   \n",
    "        for month in range(_start_month,_end):        \n",
    "            #print(year,month, _end_month, _end_year)\n",
    "            \n",
    "            if((month == _start_month) & (year == _start_year)):\n",
    "                min_day = (min(list(pda[(pda['month'] == month) & (pda['year'] == year)]['day'])))\n",
    "            else:\n",
    "                min_day = 1\n",
    "                \n",
    "            if((month == _end_month) & (year == _end_year)):\n",
    "                max_day = (max(list(pda[(pda['month'] == month) & (pda['year'] == year)]['day'])))\n",
    "                #print(month,year,max_day)\n",
    "                df_b = filla(pda,year,month,min_day=min_day, max_day=max_day,hours=hours,outcome=outcome)\n",
    "                df = pd.concat([df, df_b], ignore_index=True)\n",
    "            else:    \n",
    "                df_b =  filla(pda,year,month,min_day=min_day,hours=hours,outcome=outcome)\n",
    "                df = pd.concat([df, df_b], ignore_index=True)\n",
    "            if (year == _end_year) &  (month == _end_month):\n",
    "                #print('DONE')\n",
    "                break    \n",
    "        _start_month=1\n",
    "            \n",
    "        if year == (_end_year-1):\n",
    "            _end = _end_month + 1     \n",
    "            \n",
    "        if (year == _end_year) &  (month == _end_month):\n",
    "            #print('DONE')\n",
    "            break       \n",
    "    return df        \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_list(pda, hours=False):\n",
    "    _start_year = min(pd.unique(pda['year']))\n",
    "    _end_year = max(pd.unique(pda['year']))  \n",
    "    _start_month = min(pd.unique(pda[pda['year']== _start_year]['month']))\n",
    "    _end_month = max(pd.unique(pda[pda['year']== _end_year]['month']))\n",
    "    _end = 13\n",
    "    \n",
    "    _date_list = []\n",
    "    \n",
    "    for year in range(_start_year,_end_year+1):   \n",
    "        for month in range(_start_month,_end):        \n",
    "            #print(year,month, _end_month, _end_year)\n",
    "            \n",
    "            if((month == _start_month) & (year == _start_year)):\n",
    "                min_day = (min(list(pda[(pda['month'] == month) & (pda['year'] == year)]['day'])))\n",
    "            else:\n",
    "                min_day = 1\n",
    "            \n",
    "            if((month == _end_month) & (year == _end_year)):\n",
    "                days = (max(list(pda[(pda['month'] == month) & (pda['year'] == year)]['day'])))\n",
    "            else:\n",
    "                days = monthrange(year, month)[1]\n",
    "            \n",
    "            for day in range(min_day, days + 1):\n",
    "                if hours == True:\n",
    "                    for hour in range(0, 24):\n",
    "                        _date = get_ymdh_string(str(year),str(month),str(day),str(hour)) \n",
    "                        _date_list.append(_date) \n",
    "                else:\n",
    "                    _date = get_ymd_string(str(year),str(month),str(day))\n",
    "                    _date_list.append(_date)    \n",
    "            \n",
    "            if (year == _end_year) &  (month == _end_month):\n",
    "                #print('DONE')\n",
    "                break    \n",
    "        _start_month=1\n",
    "            \n",
    "        if year == (_end_year-1):\n",
    "            _end = _end_month + 1     \n",
    "            \n",
    "        if (year == _end_year) &  (month == _end_month):\n",
    "            #print('DONE')\n",
    "            break       \n",
    "    return _date_list        \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_fill_hours_of_month(dataframe=None,year=2022,month=7):\n",
    "    \n",
    "    days=pd.unique(dataframe['days'])\n",
    "    _start_day = min(days)\n",
    "    _end_day   = max(days)  \n",
    "\n",
    "    for day in range(_start_day,_end_day+1):\n",
    "        _df=dataframe[dataframe['days']==day] \n",
    "        for hour in range(0, 24):\n",
    "            if len(_df[_df['hours']==hour]) == 0:\n",
    "                _date = get_ymdh_string(str(year),str(month),str(day),str(hour))  \n",
    "                #print([_date,0,hour,day])\n",
    "                dataframe.loc[len(dataframe)]=[_date,0,hour,day]\n",
    "    return dataframe       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_complete(dataframe=None,year=2020):\n",
    "    for m in range(1, 13):\n",
    "        #print(m)\n",
    "        mm = dataframe[(dataframe['month'] == m) & (dataframe['year'] == year)]\n",
    "        print(m,monthrange(year, m)[1] == len(mm))\n",
    "\n",
    "def fill1(pda,year,month):        \n",
    "    days = monthrange(year, month)[1]\n",
    "    df = pda[(pda['month'] == month) & (pda['year'] == year)]\n",
    "    for day in range(1, days + 1):\n",
    "        if len(df[df['day']==day]) == 0:\n",
    "            pda.loc[len(pda)]=[get_ymd_string(str(year),str(month),str(day)),year,month,day,0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(pfall):\n",
    "    return pd.unique(pfall['CRECEIVERENDPOINTID']), pd.unique(pfall['CSTATUS']), pd.unique(pfall['CSERVICE']), pd.unique(pfall['CSENDERPROTOCOL']), pd.unique(pfall['CRECEIVERPROTOCOL'])\n",
    "\n",
    "#un=unique(pfall)\n",
    "#unique(pfall[pfall['CRECEIVERENDPOINTID']==725])\n",
    "\n",
    "#pfall0 = pfall[pfall['CRECEIVERENDPOINTID']==un[0][1]]\n",
    "#pda = createData_ymd(pfall0,0)\n",
    "\n",
    "#del pda['index'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time(object):         \n",
    "    def __init__(self,year=None,month=None,day=None):\n",
    "        self.year  = self._int_value(year)\n",
    "        self.month = self._int_value(month)\n",
    "        self.day   = self._int_value(day)\n",
    "    \n",
    "    def _int_value(self,value):\n",
    "        if value == '' or value == None:\n",
    "            return None\n",
    "        return int(value)\n",
    "        \n",
    "\n",
    "class TimeRange(object):    \n",
    "    def __init__(self,dataframe=None,year_from=None,month_from=None,day_from=None,year_to=None,month_to=None,day_to=None):\n",
    "        if dataframe is None:\n",
    "            self.start = Time(year=year_from,month=month_from,day=day_from).__dict__\n",
    "            self.end   = Time(year_to,month_to,day_to).__dict__\n",
    "        else:\n",
    "            #print(dataframe)\n",
    "            year_from = min(pd.unique(dataframe['year']))\n",
    "            year_to = max(pd.unique(dataframe['year']))  \n",
    "            month_from = min(pd.unique(dataframe[dataframe['year']== year_from]['month']))\n",
    "            month_to = max(pd.unique(dataframe[dataframe['year']== year_to]['month']))\n",
    "            day_from = min(pd.unique(dataframe[(dataframe['year']== year_from) & (dataframe['month'] == month_from)]['day']))\n",
    "            day_to = max(pd.unique(dataframe[(dataframe['year']== year_to) & (dataframe['month'] == month_to)]['day']))\n",
    "            self.start = Time(year_from,month_from,day_from).__dict__\n",
    "            self.end   = Time(year_to,month_to,day_to).__dict__\n",
    "            \n",
    "#TimeRange(dataframe=pfall).__dict__  \n",
    "\n",
    "def set_date_widget_value(element, value):\n",
    "    if value != None:\n",
    "        element.value = str(value)\n",
    "    else:\n",
    "        element.value = ''\n",
    "\n",
    "def init_date_widget(_res):\n",
    "    _range = TimeRange(dataframe=_res)\n",
    "    set_date_widget_value(year_from, _range.start['year'])\n",
    "    set_date_widget_value(month_from, _range.start['month'])\n",
    "    set_date_widget_value(day_from, _range.start['day'])\n",
    "    \n",
    "    set_date_widget_value(year_to, _range.end['year'])\n",
    "    set_date_widget_value(month_to, _range.end['month'])\n",
    "    set_date_widget_value(day_to, _range.end['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createHeatmapPfall(pfall=None,sender='all',month=1,year=2020,values='outcome',index='hours',columns='days'):\n",
    "    #print(month,year)\n",
    "    global data2\n",
    "    global piv\n",
    "    data2 = createData(pfall,month,year=year)\n",
    "    piv = pd.pivot_table(data2, values=values,index=[index], columns=[columns], fill_value=0)\n",
    "    #titlestring = \"CSENDERENDPOINTID: \" + str(topsender.iloc[7]['CSENDERENDPOINTID']) + \": \"+ category + \" so far = \" + str(topsender.iloc[7]['outcome']) + \" , month: \" + str(month) \n",
    "    #titlestring = \"CSENDERENDPOINTID: \" + str(topsender.iloc[7]['CSENDERENDPOINTID']) + \": \"+ category  + \" month: \" + str(month) \n",
    "    titlestring =\"number messages \" + str(year) + \"-\" + str(month) + \"  \" + sender\n",
    "    sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "    createHeatmap(piv, titlestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_value_submit_month(change):\n",
    "    #adapt_all()    \n",
    "    sender=0\n",
    "   \n",
    "    with out:\n",
    "        clear_output()\n",
    "        month=int(month_from.value)\n",
    "        year=int(year_from.value)\n",
    "        createHeatmapPfall(pfall0,\"endpoint \" + str(CSENDERENDPOINTID) + ' --> ' + str(CRECEIVERENDPOINTID),month=month, year=year)\n",
    "        #print(int(month_from.value), year_from.value)\n",
    "        #createHeatmapPfall(pfall=pfall,sender='all',month=1,year=2020)\n",
    "        \n",
    "        md2 = createData_ymd(pfall0,month,year=year)\n",
    "        ax=createBarplot(md2,fx=24,fy=12,fontscale=3.0,title=\"number messages \" + \"endpoint \" + str(CSENDERENDPOINTID) + ' --> ' + str(CRECEIVERENDPOINTID))\n",
    "        label(ax,1000,90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_2digits([4])\n",
    "\n",
    "pfall1 = pfall.sort_values(['year','month','day','hour']).reset_index()\n",
    "del pfall1['index']\n",
    "del pfall1['CGLOBALMESSAGEID']\n",
    "\n",
    "pfall0 = pfall\n",
    "pda = createData_ymdh(pfall0,0)\n",
    "\n",
    "check(pda)\n",
    "pfall1 = pda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(pfall['CRECEIVERENDPOINTID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRECEIVERENDPOINTID=725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall0 = pfall[pfall['CRECEIVERENDPOINTID']==725]\n",
    "pda = createData_ymd(pfall0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B\n",
    "pfall0 = pfall\n",
    "pda = createData_ymd(pfall0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pda = pda.sort_values(['date']).reset_index()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pda['index'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_complete(dataframe=pda, year=2022)\n",
    "check(pda)\n",
    "#pda\n",
    "get_month(pda, year=2022, month=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A\n",
    "fill(pda,2019,11)     \n",
    "fill(pda,2019,12) \n",
    "fill(pda,2020,1)\n",
    "fill(pda,2020,2)\n",
    "fill(pda,2020,3)\n",
    "fill(pda,2020,4)\n",
    "fill(pda,2020,5)\n",
    "fill(pda,2020,6)\n",
    "fill(pda,2020,7)\n",
    "fill(pda,2020,8)\n",
    "fill(pda,2020,9)\n",
    "fill(pda,2020,10)\n",
    "fill(pda,2020,11)\n",
    "fill(pda,2020,12)\n",
    "fill(pda,2021,1)\n",
    "fill(pda,2021,2)\n",
    "fill(pda,2021,3)\n",
    "pda = pda.sort_values(['date']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall1 = pda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_2digits([4])\n",
    "\n",
    "pfall1 = pfall.sort_values(['year','month','day','hour']).reset_index()\n",
    "del pfall1['index']\n",
    "del pfall1['CGLOBALMESSAGEID']\n",
    "\n",
    "pfall0 = pfall\n",
    "pda = createData_ymd(pfall0,0)\n",
    "\n",
    "check(pda)\n",
    "pda_day = pda.sort_values(['date']).reset_index()\n",
    "#pfall1 = pda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pda_hour = createData_ymdh(pfall0,0)\n",
    "check(pda_hour)\n",
    "pda_hour = pda_hour.sort_values(['date']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pda_minute = createData_ymdhm(pfall0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check(pda_minute)\n",
    "#pda_minute = pda_minute.sort_values(['date']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_column = 'CINBOUNDSIZE'\n",
    "_column='CMESSAGETAT2'\n",
    "pfall5 = createData_column_ymd(pfall,column=_column)\n",
    "pda_CMESSAGETAT2_day = checka(pfall5 ).sort_values(['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_column = 'CINBOUNDSIZE'\n",
    "_column='CMESSAGETAT2'\n",
    "pfall5 = createData_column_ymdh(pfall,column=_column)\n",
    "pda_CMESSAGETAT2_hour = checka(pfall5 ).sort_values(['date'])\n",
    "#pda_CINBOUNDSIZE_hour = checka(pfall5 ).sort_values(['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.renom.jp/notebooks/tutorial/time_series/lstm-anomalydetection/notebook.html\n",
    "!ls /home/jovyan/work/cls/jupyter/qtdbsel102.txt\n",
    "!ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_df =  pd.read_csv('/home/jovyan/work/cls/jupyter/spx.csv', parse_dates=['date'], index_col='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_df = pd.read_csv('/home/jovyan/work/cls/jupyter/qtdbsel102.txt', header=None, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jovyan/work/cls/jupyter/qtdbsel102.txt', header=None, delimiter='\\t')\n",
    "ecg = df.iloc[:,2].values\n",
    "ecg = ecg.reshape(len(ecg), -1)\n",
    "print('length of ECG data : ', len(ecg))\n",
    "\n",
    "# standardize\n",
    "scaler = StandardScaler()\n",
    "std_ecg = scaler.fit_transform(ecg)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('ECG\\'s value')\n",
    "plt.plot(np.arange(5000), std_ecg[:5000], color='b')\n",
    "plt.ylim(-3, 3)\n",
    "x = np.arange(4200,4400)\n",
    "y1 = [-3]*len(x)\n",
    "y2 = [3]*len(x)\n",
    "plt.fill_between(x, y1, y2, facecolor='g', alpha=.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_cycle = ecg[5000:]\n",
    "test = ecg[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_value_percent_column(df,column='outcome'):\n",
    "    return len(df[df[column] == 0]) / len(df)\n",
    "    \n",
    "print(null_value_percent_column(pda_day))\n",
    "print(null_value_percent_column(pda_hour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnull = pda_hour[(pda_hour['year'] == 2022)&(pda_hour['month'] == 7)]\n",
    "_null_column= dnull['outcome'] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnull['null'] = _null_column.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnull[dnull['null'] == 1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createHeatmap2(data2,sender='all',month=1,year=2020,values='outcome',index='hours',columns='days'):\n",
    "    piv = pd.pivot_table(data2, values=values,index=[index], columns=[columns], fill_value=0)\n",
    "    titlestring =\"number messages \" + str(year) + \"-\" + str(month) + \"  \" + sender\n",
    "    sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "    createHeatmap(piv, titlestring)\n",
    "\n",
    "createHeatmap2(dnull,sender='all',month=7,year=2022,values ='null',index='hour',columns='day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import time\n",
    "import datetime as dt\n",
    "import calendar\n",
    "import pytz\n",
    "de = pytz.timezone('Europe/Berlin')\n",
    "\n",
    "# long timestamp\n",
    "def date(x):\n",
    "    return  dt.datetime.fromtimestamp(float(x) / 1e3, tz=de)\n",
    "\n",
    "\n",
    "def adddatecolumns(data,pf,column) :\n",
    "    data['year'] = pf[column].apply(lambda x: date(x).date().year)\n",
    "    data['month'] = pf[column].apply(lambda x: date(x).date().month)\n",
    "    data['day'] = pf[column].apply(lambda x: date(x).date().day)\n",
    "    data['hour'] = pf[column].apply(lambda x: date(x).time().hour)\n",
    "    data['minute'] = pf[column].apply(lambda x: date(x).time().minute)\n",
    "    #data['second'] = pf[column].apply(lambda x: x.time().second)\n",
    "    #data['microsecond'] = pf[column].apply(lambda x: x.time().microsecond)\n",
    "\n",
    "def converttimestampcolumnn(pf,tsc) :\n",
    "    pf[tsc] = pf[tsc].apply(lambda x: dt.datetime.fromtimestamp(float(x) / 1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall0['minute'] = pfall0['CSTARTTIME'].apply(lambda x: date(x).time().minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df=pd.DataFrame(columns=['file_name', 'day', 'hour'])\n",
    "_df.loc[len(_df)]=['name',null_value_percent_column(pda_day),null_value_percent_column(pda_hour)] \n",
    "_df.loc[len(_df)]=['name',null_value_percent_column(pda_day),null_value_percent_column(pda_hour)] \n",
    "_df.to_parquet('/tmp/null_values.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "null_percent = pd.read_parquet('/tmp/null_values.parquet')\n",
    "null_percent_day.columns = ['file', 'day', 'hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percent_day = null_percent.sort_values(['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_file = null_percent_day.iloc[0]['file']\n",
    "#df = sparkSession.read.parquet('/tmp/enc/' + _file)\n",
    "\n",
    "_file1 = null_percent_day.iloc[1]['file']\n",
    "#df = sparkSession.read.parquet('/tmp/enc/' + _file , '/tmp/enc/' + _file1)\n",
    "df = sparkSession.read.parquet(*flist)\n",
    "\n",
    "pfall9 = df.toPandas() \n",
    "\n",
    "len(pfall9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall = pfall9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listi = list(null_percent_day['file'])\n",
    "flist = \",\".join('/tmp/enc/' + s for s in listi).split(',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pfall9)\n",
    "pfall9\n",
    "flist = ['/tmp/enc/' + _file , '/tmp/enc/' + _file1]\n",
    "type (flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df=pd.DataFrame(columns=['file', 'day', 'hour'])\n",
    "for file in _files:\n",
    "    try:\n",
    "        #print(file)\n",
    "        df = sparkSession.read.parquet('/tmp/enc/' + file)\n",
    "        pfall = df.toPandas() \n",
    "        \n",
    "        make_2digits([4])\n",
    "\n",
    "        pfall1 = pfall.sort_values(['year','month','day','hour']).reset_index()\n",
    "        del pfall1['index']\n",
    "        del pfall1['CGLOBALMESSAGEID']\n",
    "\n",
    "        pfall0 = pfall\n",
    "        pda = createData_ymd(pfall0,0)\n",
    "\n",
    "        check(pda)\n",
    "        pda_day = pda.sort_values(['date']).reset_index()\n",
    "        \n",
    "        pda_hour = createData_ymdh(pfall0,0)\n",
    "        check(pda_hour)\n",
    "        pda_hour = pda_hour.sort_values(['date']).reset_index()\n",
    "        \n",
    "        _df.loc[len(_df)]=[file,null_value_percent_column(pda_day),null_value_percent_column(pda_hour)] \n",
    "        _df.to_parquet('/tmp/null_values.parquet')\n",
    "    except Exception as exception:    \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall[pfall['year'] == 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pda_CMESSAGETAT2_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   \n",
    "#pda.reset_index()\n",
    "#del(pda['index'])\n",
    "#pfall2 = pda[(pda['year']==2019) & (pda['month']==10)].sort_values(['date']).reset_index()\n",
    "pfall2 = pda[(pda['year']==2021)].sort_values(['date']).reset_index()\n",
    "del pfall2['index']\n",
    "#del pfall2['level_0']\n",
    "pfall2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(pfall2)\n",
    "pfall2.sort_values(['date']).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pfall2.sort_values(['date']).reset_index()\n",
    "pfall2[(pfall2['year']==2019) & (pfall2['month']==10)].sort_values(['date']).reset_index()\n",
    "\n",
    "#check(pfall2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del pfall2['index']\n",
    "#check(pfall2)\n",
    "pfall2 = pfall2[(pfall2['year']==2019)].sort_values(['date']).reset_index()\n",
    "pfall2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pda\n",
    "md = createData_ym(pfall1,0)\n",
    "ax=createBarplot(md,24,12,3.0,title=\"number messages sent by all endpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#md\n",
    "# 12.07.2022 (10:00 Uhr) bis 13.07.2022 (15:00 Uhr) \n",
    "#del pfall1['index']\n",
    "pfall1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md2 = createData_ymdh(pfall1,7,year=2022)\n",
    "ax=createBarplot(md2,fx=24,fy=12,fontscale=3.0,title=\"number messages sent by all endpoints\")\n",
    "label(ax,1000,90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md3=createData(pda_CMESSAGETAT2_hour,7,year=2022)\n",
    "#md3=md3[(md3['days'] == 11) | (md3['days'] == 12) | (md3['days'] == 13)].reset_index()\n",
    "#del(md3['index'])\n",
    "_df =  check_and_fill_hours_of_month(dataframe=md3,year=2022,month=7).sort_values(['date']).reset_index()     \n",
    "\n",
    "fig = plt.figure(figsize=(18,9))\n",
    "plt.plot(_df.index, _df.outcome, label='msg count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pda_CMESSAGETAT2_hour\n",
    "_df = _df[(_df['year'] == 2022) & (_df['month'] == 7) ].reset_index()  \n",
    "#_df = _df[(_df['year'] == 2022) & (_df['month'] == 7) & (_df['day'] == 12)].reset_index() \n",
    "\n",
    "fig = plt.figure(figsize=(18,9))\n",
    "plt.plot(_df.index, _df.outcome, label='msg count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "pfall2 = pfall1[(pfall1['year'] == 2022) & (pfall1['month'] == 7)  & (pfall1['day'].isin([10,11,12,13]))].sort_values(['date'] )\n",
    "del(pfall2['index'])\n",
    "check(pfall2)\n",
    "pfall2=pfall2.sort_values(['date'] ).reset_index()\n",
    "del(pfall2['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(18,9))\n",
    "plt.plot(pfall2.index, pfall2.outcome, label='msg count');\n",
    "#plt.plot(pfall2.date, pfall2.outcome, label='msg count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pfall[(pfall['year'] == year) & (pfall['month'] == month)].groupby(['year','month','day','hour'])['year'].count()\n",
    "md2['outcome'].sum()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createHeatmapPfall(pfall=pfall,sender='all',month=7,year=2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hbox init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout2 = {'width': '400px'}\n",
    "\n",
    "year_from   = widgets.Text(description = 'year',value = '2020', style=style, layout=layout2,disabled=False)   \n",
    "year_to     = widgets.Text(description = 'to',value = '', style={'description_width': '20px'}, layout={'width': '200px'},disabled=False)  \n",
    "#year_hbox = widgets.HBox([year_from,year_to])\n",
    "year_hbox = widgets.HBox([year_from])\n",
    "\n",
    "#month  = widgets.Text(description = 'month',value = '', style=style, layout=layout,disabled=False) \n",
    "month_from   = widgets.Text(description = 'month',value = '1', style=style, layout=layout2,disabled=False)   \n",
    "month_to     = widgets.Text(description = 'to',value = '', style={'description_width': '20px'}, layout={'width': '200px'},disabled=False)  \n",
    "#month_hbox   = widgets.HBox([month_from,month_to])\n",
    "month_hbox   = widgets.HBox([month_from])\n",
    "\n",
    "day_from   = widgets.Text(description = 'day',value = '', style=style, layout=layout2,disabled=False)   \n",
    "day_to     = widgets.Text(description = 'to',value = '', style={'description_width': '20px'}, layout={'width': '200px'},disabled=False)  \n",
    "day_hbox   = widgets.HBox([day_from,day_to])\n",
    "\n",
    "month_from.on_submit(on_value_submit_month)\n",
    "year_from.on_submit(on_value_submit_month)\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "display (year_hbox,month_hbox,out)\n",
    "#init_date_widget(pfall)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2\n",
    "#TimeRange(dataframe=pfall).__dict__\n",
    "_pf = pfall.drop_duplicates(subset=['month','day','year'])\n",
    "#_pf[(_pf['month'] == 1) & (_pf['year'] == 2020)]\n",
    "_pf = pfall[['month','day','year']].drop_duplicates()\n",
    "\n",
    "_days = len(_pf[(_pf['month'] == 10) & (_pf['year'] == 2019)]) \\\n",
    "+ len(_pf[(_pf['month'] == 11) & (_pf['year'] == 2019)]) \\\n",
    "+ len(_pf[(_pf['month'] == 12) & (_pf['year'] == 2019)]) \\\n",
    "+ len(_pf[(_pf['month'] == 1) & (_pf['year'] == 2020)]) \\\n",
    "+ len(_pf[(_pf['month'] == 2) & (_pf['year'] == 2020)]) \\\n",
    "+ 18 , len(_pf)\n",
    "_days[0] / _days[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeRange(dataframe=pfall).__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# configure our pipeline\n",
    "pipeline = Pipeline([('normalizer', Normalizer()),\n",
    "                     ('scaler', MinMaxScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall1= pfall6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Anomaly Detection with LSTM Autoencoders (selected sender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_period(anomalyEnc):\n",
    "    return anomalyEnc.train.index[0], anomalyEnc.train.index[len(anomalyEnc.train.index)-1]\n",
    "\n",
    "def get_test_period(anomalyEnc):\n",
    "    return anomalyEnc.test.index[0], anomalyEnc.test.index[len(anomalyEnc.test) -1]\n",
    "\n",
    "def get_period(pfall,percent = 1.0):\n",
    "    max_index = int(len(pfall1) * percent)\n",
    "    return pfall.iloc[pfall.index[0]]['date'], pfall.iloc[pfall.index[max_index -1]]['date']\n",
    "\n",
    "def get_percent(pfall1,year=None,month=None,day=None,hour=None):\n",
    "    _pfall = pfall1[(pfall1['year'] == year) & (pfall1['month'] == month)]\n",
    "    if day != None:\n",
    "        _pfall = _pfall[(_pfall['day'] == day)]\n",
    "    if hour != None:\n",
    "        _pfall = _pfall[(_pfall['hour'] == hour)]\n",
    "    \n",
    "    index = _pfall.index[len(_pfall.index)-1]    \n",
    "    #print(index)\n",
    "    index = pfall1.index.get_loc(index)\n",
    "    \n",
    "    return (index + 1) / len(pfall1)\n",
    "    #return _pfall.index\n",
    "    \n",
    "def get_index_period(pfall):\n",
    "    max_index = int(len(pfall) * percent) -1\n",
    "    return pfall.index[0], pfall.index[max_index]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "print(get_trained_period(anomalyEnc1), get_test_period(anomalyEnc1))\n",
    "print(get_trained_period(anomalyEnc2), get_test_period(anomalyEnc2))\n",
    "print(get_trained_period(anomalyEnc3), get_test_period(anomalyEnc3))\n",
    "print(get_trained_period(anomalyEnc4), get_test_period(anomalyEnc4))\n",
    "#print(get_period(pfall1,0.7))\n",
    "#get_percent(pfall1,year=2022,month=6,day=None,hour=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pfall = pda_hour\n",
    "_pfall.index[len(_pfall.index)-1]\n",
    "_pfall.index.get_loc('2022-10-06-23')\n",
    "#get_percent(pda_hour,year=2022,month=6,day=None,hour=None)\n",
    "len(_pfall.index)-1\n",
    "\n",
    "index = _pfall.index.get_loc('2022-06-30-23')\n",
    "#(index + 1) , len(_pfall)\n",
    "index, len(_pfall)\n",
    "get_percent(pda_hour,year=2022,month=6,day=None,hour=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEnc.train.index\n",
    "pfall1.iloc[17908 - 1]\n",
    "#int(len(pfall1) * TRAIN_SIZE)\n",
    "pfall1\n",
    "#int(len(pfall1) * 1.0)\n",
    "year = 2022\n",
    "month = 10\n",
    "day = 4\n",
    "hour = 23\n",
    "index = pfall1[(pfall1['year'] == year) & (pfall1['month'] == month) & (pfall1['day'] == day) & (pfall1['hour'] == hour)].index[0]\n",
    "(index + 1) / len(pfall1)\n",
    "\n",
    "print(get_period(pfall1,get_percent(pfall1,year=2022,month=6,day=None,hour=None)))\n",
    "#len(get_percent(pfall1,year=2022,month=10,day=None,hour=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.7\n",
    "train_size = int(len(pfall1) * TRAIN_SIZE)\n",
    "test_size = len(pfall1) - TRAIN_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_index_by_date_column(df):\n",
    "    df.set_index(df['date'], inplace=True)\n",
    "    #del df['index']\n",
    "    #del df['date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AnomalyDetectionLSTMAutoencoder\n",
    "\n",
    "def train_model(dataframe=None, time_steps=30, year=2022,month=6,day=None,hour=None):\n",
    "    anomalyEnc = AnomalyDetectionLSTMAutoencoder.AnomalyDetectionLSTMAutoencoder(TIME_STEPS = time_steps)\n",
    "    #anomalyEnc.initAndTrain_divide(dataframe, get_percent(dataframe,year=year,month=month,day=day,hour=hour))\n",
    "    \n",
    "    anomalyEnc.df1 = anomalyEnc.createDataframe(dataframe)\n",
    "    perc_train = get_percent(dataframe,year=year,month=month,day=day,hour=hour)\n",
    "    train, test = anomalyEnc.getTrainAndTest(anomalyEnc.df1,perc_train)\n",
    "    anomalyEnc.initAndTrain(train=train, test=test)\n",
    "    \n",
    "    return anomalyEnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_dataframe(b):\n",
    "    _df = pd.DataFrame()\n",
    "    _df['outcome'] = b.reshape([1, len(b)])[0]\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEnc2 = AnomalyDetectionLSTMAutoencoder.AnomalyDetectionLSTMAutoencoder(TIME_STEPS = 30)\n",
    "spx_df.columns = ['outcome']\n",
    "anomalyEnc2.df1 = anomalyEnc2.createDataframe(spx_df)\n",
    "train, test = anomalyEnc2.getTrainAndTest(anomalyEnc2.df1,0.7)\n",
    "anomalyEnc2.initAndTrain(train=train, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_df.columns = ['outcome']\n",
    "\n",
    "anomalyEnc2 = AnomalyDetectionLSTMAutoencoder.AnomalyDetectionLSTMAutoencoder(TIME_STEPS = 30)\n",
    "anomalyEnc2.initAndTrain_divide(spx_df,0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_cycle = numpy_to_dataframe(ecg[5000:])\n",
    "test = numpy_to_dataframe(ecg[:5000])\n",
    "\n",
    "anomalyEnc = AnomalyDetectionLSTMAutoencoder.AnomalyDetectionLSTMAutoencoder(TIME_STEPS = 100, OUTCOME='outcome')\n",
    "anomalyEnc.initAndTrain(train=normal_cycle, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEnc.OUTCOME\n",
    "anomalyEnc.initAndTrain(train=normal_cycle, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= normal_cycle\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train[['outcome']])\n",
    "train[['outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_index_by_date_column(pda_CINBOUNDSIZE_hour)\n",
    "pda_CINBOUNDSIZE_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEnc7 = train_model(dataframe=pda_CINBOUNDSIZE_hour, time_steps=24 * 7, year=2022,month=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_index_by_date_column(pda_hour)\n",
    "replace_index_by_date_column(pda_CMESSAGETAT2_hour)\n",
    "replace_index_by_date_column(pda_day)\n",
    "replace_index_by_date_column(pda_CMESSAGETAT2_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEncB6 = train_model(dataframe=_pda_hour, time_steps=24, year=2022,month=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEncC1 = train_model(dataframe=pda_CMESSAGETAT2_day, time_steps=30, year=2022,month=6)\n",
    "anomalyEncC2 = train_model(dataframe=pda_day, time_steps=30, year=2022,month=6)\n",
    "\n",
    "anomalyEncC3 = train_model(dataframe=pda_CMESSAGETAT2_hour, time_steps=24 * 7, year=2022,month=6)\n",
    "anomalyEncC4 = train_model(dataframe=pda_hour, time_steps=24 * 7, year=2022,month=6)\n",
    "\n",
    "anomalyEncC5 = train_model(dataframe=pda_CMESSAGETAT2_hour, time_steps=24, year=2022,month=6)\n",
    "anomalyEncC6 = train_model(dataframe=pda_hour, time_steps=24, year=2022,month=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pda_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anomalyEnc4 = AnomalyDetectionLSTMAutoencoder.AnomalyDetectionLSTMAutoencoder(TIME_STEPS = 24 * 7)\n",
    "#anomalyEnc4.initAndTrain(pda_hour, get_percent(pda_hour,year=2022,month=6,day=None,hour=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anomalyEnc3 = AnomalyDetectionLSTMAutoencoder.AnomalyDetectionLSTMAutoencoder(TIME_STEPS = 24 * 7)\n",
    "#anomalyEnc3.initAndTrain(pda_CMESSAGETAT2_hour, get_percent(pda_CMESSAGETAT2_hour,year=2022,month=6,day=None,hour=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "#import AnomalyDetectionLSTMAutoencoder\n",
    "#anomalyEnc2 = AnomalyDetectionLSTMAutoencoder.AnomalyDetectionLSTMAutoencoder(TIME_STEPS = 30)\n",
    "#anomalyEnc2.initAndTrain(pda_CMESSAGETAT2_day,0.7)\n",
    "#anomalyEnc2.initAndTrain(pda_CMESSAGETAT2_day, get_percent(pda_CMESSAGETAT2_day,year=2022,month=6,day=None,hour=None))\n",
    "\n",
    "#anomalyEnc1 = AnomalyDetectionLSTMAutoencoder.AnomalyDetectionLSTMAutoencoder(TIME_STEPS = 30)\n",
    "#anomalyEnc1.initAndTrain(pda_day,0.7)\n",
    "#anomalyEnc1.initAndTrain(pda_day, get_percent(pda_day,year=2022,month=6,day=None,hour=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pda_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_trained_period(anomalyEnc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pfall1),  len(anomalyEnc.train), len(anomalyEnc.test), len(anomalyEnc.y_test), len(anomalyEnc.df1), len(anomalyEnc.train), len(anomalyEnc.test),anomalyEnc.TIME_STEPS, len(anomalyEnc.X_train), len(anomalyEnc.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "import numpy as np\n",
    "\n",
    "#anomalyEnc.test_score_df      = anomalyEnc.testScoreDF(anomalyEnc.model, 0.0, anomalyEnc.X_test, anomalyEnc.test)\n",
    "\n",
    "#plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False) \n",
    "#data = plt.plot(anomalyEnc.test_score_df.index, anomalyEnc.test_score_df.loss, label='loss')\n",
    "\n",
    "#y=plt.getp(data[0],'ydata')\n",
    "\n",
    "#threshold_X = 0.98 * np.max(y)\n",
    "#threshold_X = np.max(y) - 0.0001\n",
    "#anomalyEnc.evaluateAnomalies(threshold_X)\n",
    "\n",
    "\n",
    "data = sns.distplot(anomalyEnc2.train_mae_loss, bins=50, kde=True).get_lines()[0].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "style = {'description_width': '250px'}\n",
    "layout = {'width': '600px'}\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "#anomalyEnc.test_score_df      = anomalyEnc.testScoreDF(anomalyEnc.model, 0.0, anomalyEnc.X_test, anomalyEnc.test)\n",
    "\n",
    "def getThreshold(perc,anomalyEnc):\n",
    "    out2 = widgets.Output()\n",
    "    with out2:\n",
    "        anomalyEnc.test_score_df      = anomalyEnc.testScoreDF(anomalyEnc.model, 0.0, anomalyEnc.X_test, anomalyEnc.test)\n",
    "        fig = plt.figure(figsize=(12,6))\n",
    "        plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False) \n",
    "        data = plt.plot(anomalyEnc.test_score_df.index, anomalyEnc.test_score_df.loss, label='loss')\n",
    "        y=plt.getp(data[0],'ydata')\n",
    "        plt.show(fig)\n",
    "\n",
    "    #threshold_X = np.max(y) - 0.025\n",
    "    return perc * np.max(y)\n",
    "\n",
    "#out2 = widgets.Output()\n",
    "#with out2:\n",
    "#    threshold_X = getThreshold(0.88)\n",
    "    \n",
    "#threshold_X    \n",
    "\n",
    "#anomalyEnc.evaluateAnomalies(threshold_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anomalyEnc1.X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomalyEnc2.test_score_df      = anomalyEnc2.testScoreDF(anomalyEnc2.model, 0.0, anomalyEnc2.X_test, anomalyEnc2.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot(index, values,label):\n",
    "    return sns.scatterplot(\n",
    "      x=index,\n",
    "      y=values,\n",
    "      color=sns.color_palette()[3],\n",
    "      s=152,\n",
    "      label=label\n",
    "    )\n",
    "    \n",
    "def plot_test(test,scaler,anomalies,titlestring,xlabel):\n",
    "\n",
    "    fig = plt.figure(figsize=(18,9))\n",
    "    \n",
    "    plt.plot(\n",
    "      test[anomalyEnc.TIME_STEPS:].index, \n",
    "      #scaler.inverse_transform(test[TIME_STEPS:].close), \n",
    "      scaler.inverse_transform(test[anomalyEnc.TIME_STEPS:]),   \n",
    "      label='msg count'\n",
    "    );\n",
    "\n",
    "    #ax = scatterplot(anomalyEnc.anomalies.index, anomalyEnc.scaler.inverse_transform(anomalyEnc.anomalies['close']), 'anomaly')  \n",
    "    #ax = scatterplot(anomalyEnc.anomalies.index, anomalyEnc.scaler.inverse_transform(anomalyEnc.anomalies), 'anomaly')\n",
    "    _a=anomalyEnc.anomalies['close']\n",
    "    _a = pd.DataFrame(_a)\n",
    "    _a = anomalyEnc.scaler.inverse_transform(_a)\n",
    "    _a = _a[:, 0]\n",
    "    #print(_a,type(_a),_a[0],len(_a),len(_a[:, 0]))\n",
    "    ax = scatterplot(anomalyEnc.anomalies.index, _a, 'anomaly') \n",
    "    \n",
    "    ax.set_xlabel(xlabel)\n",
    "    plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False) \n",
    "    plt.xticks(rotation=25)\n",
    "    plt.legend();\n",
    "\n",
    "    label(ax,5,80)\n",
    "    plt.title(titlestring)\n",
    "    plt.show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEnc.anomalies.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEnc3.anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Problems / Erwartungsmonitoring\n",
    "\n",
    "- am 12.07.2022 wurde ein BIS Release installiert dass zur Verzögerung vieler Nachrichten geführt hat.\n",
    "Die letzten Nachrichten wurden am Folgetag um ca. 15:00 Uhr CET verarbeitet.\n",
    "Es sollten also deutliche Anomalien zwischen 12.07.2022 (10:00 Uhr) bis 13.07.2022 (15:00 Uhr) zu sehen sein.\n",
    "\n",
    "\n",
    "- 13.09.2022 19:00 Uhr / 20:00 Uhr UTC: Massive Last, Anflutung des Systems, vor allem im zweiten Intervall.\n",
    "Durchlaufzeiten waren deutlich erhöht. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pda_CMESSAGETAT2_hour\n",
    "_df = pd.DataFrame()        \n",
    "_df['outcome'] = data3['outcome']\n",
    "_df.set_index(data3['date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pda_CMESSAGETAT2_hour.set_index(pda_CMESSAGETAT2_hour['date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pda_CMESSAGETAT2_hour\n",
    "_df = pda_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df2.index[_df2.index.str.contains('-00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pda_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Problems / Erwartungsmonitoring\n",
    "\n",
    "- am 12.07.2022 wurde ein BIS Release installiert dass zur Verzögerung vieler Nachrichten geführt hat.\n",
    "Die letzten Nachrichten wurden am Folgetag um ca. 15:00 Uhr CET verarbeitet.\n",
    "Es sollten also deutliche Anomalien zwischen 12.07.2022 (10:00 Uhr) bis 13.07.2022 (15:00 Uhr) zu sehen sein.\n",
    "\n",
    "\n",
    "- 13.09.2022 19:00 Uhr / 20:00 Uhr UTC: Massive Last, Anflutung des Systems, vor allem im zweiten Intervall.\n",
    "Durchlaufzeiten waren deutlich erhöht. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(_df,contains=None, y='outcome'):\n",
    "    _df2 = _df[_df.index.str.contains(contains)]\n",
    "\n",
    "    fig = plt.figure(figsize=(18,9))\n",
    "    \n",
    "    hours= False\n",
    "    \n",
    "    plt.plot(_df2.index, _df2[y], label=y)\n",
    "    if len(_df2.index[0].split('-')) == 4:\n",
    "        hours = True\n",
    "        ticks=_df2.index[_df2.index.str.contains('-00')]\n",
    "        ticks2 = list(ticks)\n",
    "        ticks2.append('2022-07-12-10')\n",
    "        ticks2.append('2022-07-13-15')\n",
    "        ticks2.sort()\n",
    "        ticks = ticks2\n",
    "    elif len(_df2.index[0].split('-')) == 3:\n",
    "        ticks=list(_df2.index[_df2.index.str.contains('-01')])  \n",
    "        for day in range(2,10):\n",
    "            ticks.remove('2022-01-0' + str(day))\n",
    "        for day in range(10,32):\n",
    "            ticks.remove('2022-01-' + str(day)) \n",
    "        b=(len(ticks)-1)    \n",
    "        ticks = ticks[:6] + ['2022-07-12'] + ticks[6:b]     \n",
    "    else:\n",
    "        ticks=_df2.index\n",
    "    #ticks=[_df2.index[0]]\n",
    "    \n",
    "    #12.07.2022 (10:00 Uhr) bis 13.07.2022 (15:00 Uhr)\n",
    "    if hours == False:\n",
    "        plt.axvline(x='2022-07-12', color=\"red\")\n",
    "        plt.axvline(x='2022-09-13', color=\"red\")\n",
    "    else:    \n",
    "         plt.axvline(x='2022-07-12-10', color=\"red\")\n",
    "         plt.axvline(x='2022-07-13-15', color=\"red\")\n",
    "         #plt.axvline(x='2022-09-13-19', color=\"red\")\n",
    "         #plt.axvline(x='2022-09-13-20', color=\"red\")\n",
    "       \n",
    "    #print(ticks)\n",
    "    \n",
    "    plt.legend();\n",
    "    plt.xticks(rotation=80,ticks=ticks)\n",
    "    plt.show(fig)\n",
    "    return ticks    \n",
    "\n",
    "\n",
    "\n",
    "def plot_graph2(test=None, expect=None, column_y='outcome',contains=None, date_from=None, date_to=None):\n",
    "        \n",
    "    _test =test\n",
    "    \n",
    "    if contains is not None:\n",
    "        _test = _test[_test.index.str.contains(contains)]\n",
    "        #anomalies = anomalies[anomalies.index.str.contains(contains)]\n",
    "    elif date_from is not None and date_to is not None:\n",
    "        _from_index = _test.index.get_loc(date_from)\n",
    "        _to_index   = _test.index.get_loc(date_to)\n",
    "        #_df2 = _df2[_df2.index[_from_index:_to_index + 1]]\n",
    "        _test = _test.iloc[_from_index:_to_index + 1]\n",
    "    else:\n",
    "        pass    \n",
    "            \n",
    "    fig = plt.figure(figsize=(18,9))\n",
    "    plt.plot(_test.index, _test[column_y])       \n",
    "    \n",
    "    ticks = (_test.index[0], _test.index[len(_test.index) - 1])\n",
    "    plt.xticks(rotation=80,ticks=ticks)\n",
    "    \n",
    "    if expect is not None:\n",
    "        #print(_test.index.get_loc(expect[0]),_test.index.get_loc(expect[1]))\n",
    "        e1=_test.index.get_loc(expect[0])\n",
    "        e2=_test.index.get_loc(expect[1])\n",
    "        x = np.arange(e1,e2)\n",
    "        #x = np.arange(expect[0],expect[1])\n",
    "        _max = np.max(_test[column_y])\n",
    "        y1 = [0]*len(x)\n",
    "        y2 = [_max]*len(x)\n",
    "        plt.fill_between(x, y1, y2, facecolor='g', alpha=.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_date = get_ymdh_string(pfall4['year'], pfall4['month'], pfall4['day'],pfall4['hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall4 = pfall[(pfall['year']==2022) & ((pfall['month']==7) | (pfall['month']==6))].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall4.columns\n",
    "#pfall4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dates = get_date_list(pfall, hours=False)\n",
    "#_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_column = 'CSLATAT'\n",
    "pfall6=checka(pfall4, outcome=_column )\n",
    "pfall6.set_index(pfall6['date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_column = 'CINBOUNDSIZE'\n",
    "pfall6=checka(pfall4, outcome=_column )\n",
    "pfall6.set_index(pfall6['date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_graph(pfall6, contains = '2022-', y=_column ) \n",
    "ticks = plot_graph(pfall6, contains = '2022-07-1', y=_column )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_column = 'CINBOUNDSIZE'\n",
    "pfall7 = pda_CINBOUNDSIZE_hour[(pda_CINBOUNDSIZE_hour['year']==2022) & ((pda_CINBOUNDSIZE_hour['month']==7) | (pda_CINBOUNDSIZE_hour['month']==6))].reset_index()\n",
    "pfall7=checka(pfall7 )\n",
    "pfall7.set_index(pfall7['date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pfall7\n",
    "ticks = plot_graph(pfall7, contains = '2022-07-1', y='outcome' )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall7[pfall7['outcome'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2\n",
    "#pfall4\n",
    "#pd.concat([pfall4, _date], axis=1)\n",
    "#pfall4.set_index(_date, inplace=True)\n",
    "\n",
    "pfall4['date'] = _date\n",
    "pfall4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall4.loc['2022-07-07-08']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall4 = pfall4.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(pda_day, contains = '2022-')   \n",
    "plot_graph(pda_CMESSAGETAT2_day, contains = '2022-')  \n",
    "plot_graph(pda_hour, contains = '2022-07')   \n",
    "plot_graph(pda_CMESSAGETAT2_hour, contains = '2022-07')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(pda_CMESSAGETAT2_hour, contains = '2022-07')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(pda_hour, contains = '2022-07-')    \n",
    "plot_graph(pda_CMESSAGETAT2_hour, contains = '2022-07-')        \n",
    "plot_graph(pda_hour, contains = '2022-09-')    \n",
    "plot_graph(pda_CMESSAGETAT2_hour, contains = '2022-09-')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filtered plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform_anomalies(scaler=None,anomalies=None, column_y='close'):\n",
    "    _a = anomalies[column_y]\n",
    "    _a = pd.DataFrame(_a)\n",
    "    _a = scaler.inverse_transform(_a)\n",
    "    _a = _a[:, 0]\n",
    "    return _a\n",
    "\n",
    "def filtered_plot(test=None,scaler=None,anomalies=None,TIME_STEPS=None,contains=None, date_from=None, date_to=None,titlestring='',xlabel='',skip=None,rotate=80):\n",
    "    #_df2 = test[TIME_STEPS:]\n",
    "    _df2 = test\n",
    "    \n",
    "    if contains is not None:\n",
    "        _df2 = _df2[_df2.index.str.contains(contains)]\n",
    "        anomalies = anomalies[anomalies.index.str.contains(contains)]\n",
    "    elif date_from is not None and date_to is not None:\n",
    "        _from_index = _df2.index.get_loc(date_from)\n",
    "        _to_index   = _df2.index.get_loc(date_to)\n",
    "        #_df2 = _df2[_df2.index[_from_index:_to_index + 1]]\n",
    "        _df2 = _df2.iloc[_from_index:_to_index + 1]\n",
    "        \n",
    "        anomalies = anomalies.iloc[_from_index:_to_index + 1]\n",
    "        \n",
    "        for date in anomalyEnc6.anomalies.index:\n",
    "            if date >= '2022-07-01-00':\n",
    "                _min = anomalyEnc6.anomalies.index.get_loc(date)\n",
    "                break     \n",
    "        for _max in range(_min,len(anomalyEnc6.anomalies.index)):\n",
    "            if anomalyEnc6.anomalies.index[_max] > '2022-07-07-23':\n",
    "                break\n",
    "        anomalies = anomalies.iloc[_min:_max]         \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    _a = inverse_transform_anomalies(scaler=scaler,anomalies=anomalies, column_y='close')\n",
    "    \n",
    "    fig = plt.figure(figsize=(30,12))\n",
    "\n",
    "    plt.plot(\n",
    "      _df2.index,  \n",
    "      scaler.inverse_transform(_df2),   \n",
    "      label='msg count'\n",
    "    );\n",
    "\n",
    "    ax = scatterplot(anomalies.index, _a, 'anomaly') \n",
    "\n",
    "    if skip is not None:\n",
    "        label(ax,skip,rotate)\n",
    "    \n",
    "    hours= False\n",
    "    if len(_df2.index[0].split('-')) == 4:\n",
    "        hours = True\n",
    "    if hours == False:\n",
    "        plt.axvline(x='2022-07-12', color=\"red\")\n",
    "        #plt.axvline(x='2022-07-13', color=\"red\")\n",
    "        #plt.axvline(x='2022-09-13', color=\"red\")\n",
    "    else:    \n",
    "        plt.axvline(x='2022-07-12-10', color=\"red\")\n",
    "        plt.axvline(x='2022-07-13-15', color=\"red\")\n",
    "        #plt.axvline(x='2022-09-13-19', color=\"red\")\n",
    "        #plt.axvline(x='2022-09-13-20', color=\"red\")\n",
    "        \n",
    "    plt.title(titlestring)\n",
    "    #plt.show(fig)     \n",
    "        \n",
    "def filtered_plot_enc(anomalyEnc, contains=None,date_from=None, date_to=None,titlestring='',xlabel='',skip=None,rotate=80):     \n",
    "    return filtered_plot(anomalyEnc.test,anomalyEnc.scaler,anomalyEnc.anomalies,anomalyEnc.TIME_STEPS,contains,date_from, date_to,titlestring,xlabel,skip,rotate)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_plot2(test=None,scaler=None,anomalies=None,TIME_STEPS=None,contains=None, date_from=None, date_to=None,titlestring='',xlabel='',skip=None,rotate=80, annotations=True, ylabel='msg count'):\n",
    "    #_df2 = test[TIME_STEPS:]\n",
    "    _df2 = test\n",
    "    \n",
    "    if contains is not None:\n",
    "        _df2 = _df2[_df2.index.str.contains(contains)]\n",
    "        anomalies = anomalies[anomalies.index.str.contains(contains)]\n",
    "    elif date_from is not None and date_to is not None:\n",
    "        _from_index = _df2.index.get_loc(date_from)\n",
    "        _to_index   = _df2.index.get_loc(date_to)\n",
    "        #_df2 = _df2[_df2.index[_from_index:_to_index + 1]]\n",
    "        _df2 = _df2.iloc[_from_index:_to_index + 1]\n",
    "       \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    _a = anomalies['close']\n",
    "    _a = pd.DataFrame(_a)\n",
    "    _a = scaler.inverse_transform(_a)\n",
    "    _a = _a[:, 0]\n",
    "    \n",
    "    fig = plt.figure(figsize=(30,12))\n",
    "\n",
    "    plt.plot(\n",
    "      _df2.index,  \n",
    "      scaler.inverse_transform(_df2),   \n",
    "      label=ylabel\n",
    "    );\n",
    "\n",
    "    ax = scatterplot(anomalies.index, _a, 'anomaly') \n",
    "\n",
    "    if skip is not None:\n",
    "        label(ax,skip,rotate)\n",
    "    \n",
    "    hours= False\n",
    "    if len(_df2.index[0].split('-')) == 4:\n",
    "        hours = True\n",
    "        \n",
    "    if annotations == True:    \n",
    "        if hours == False:\n",
    "            plt.axvline(x='2022-07-12', color=\"red\")\n",
    "            #plt.axvline(x='2022-07-13', color=\"red\")\n",
    "            #plt.axvline(x='2022-09-13', color=\"red\")\n",
    "        else:    \n",
    "            plt.axvline(x='2022-07-12-10', color=\"red\")\n",
    "            plt.axvline(x='2022-07-13-15', color=\"red\")\n",
    "            #plt.axvline(x='2022-09-13-19', color=\"red\")\n",
    "            #plt.axvline(x='2022-09-13-20', color=\"red\")\n",
    "        \n",
    "    plt.title(titlestring)\n",
    "    #plt.show(fig)     \n",
    "        \n",
    "\n",
    "def filtered_plot_enc2(anomalyEnc, contains=None,date_from=None, date_to=None,titlestring='',xlabel='',skip=None,rotate=80, annotations=True, ylabel='msg count'):     \n",
    "    return filtered_plot2(anomalyEnc.test,anomalyEnc.scaler,anomalyEnc.anomalies,anomalyEnc.TIME_STEPS,contains,date_from, date_to,titlestring,xlabel,skip,rotate, annotations=annotations, ylabel=ylabel)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_plot_enc2(anomalyEncC5,date_from='2022-09-01-00', date_to='2022-10-03-00',skip=50,rotate=80,titlestring= 'trained: ' + str(get_trained_period(anomalyEncC6)) + ' , time_steps=24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contains='2022-07'\n",
    "_df2 = anomalyEnc6.anomalies\n",
    "#_df2[_df2.index.str.contains('2022-07-')]\n",
    "#len(_df2)\n",
    "_df2[_df2.index.str.contains(contains)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEnc6.test.loc['2022-10-06-14'].index\n",
    "_from_index = anomalyEnc6.test.index.get_loc('2022-07-01-00')\n",
    "_to_index = anomalyEnc6.test.index.get_loc('2022-07-15-00')\n",
    "\n",
    "#anomalyEnc6.test.iloc[_index]\n",
    "_from_index,_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anomalyEnc6.test.iloc[anomalyEnc6.test.index[_from_index:_to_index + 1]]\n",
    "\n",
    "#anomalyEnc6.test.iloc[_from_index:_to_index + 1]\n",
    "for date in anomalyEnc6.anomalies.index:\n",
    "    if date >= '2022-07-01-00':\n",
    "        _min = anomalyEnc6.anomalies.index.get_loc(date)\n",
    "        break     \n",
    "for _max in range(_min,len(anomalyEnc6.anomalies.index)):\n",
    "    if anomalyEnc6.anomalies.index[_max] > '2022-07-07-23':\n",
    "        break\n",
    "        \n",
    "_min,_max        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEnc6.anomalies.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'2022-07-01-00' > '2022-07-07-23'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel Anomalie / messages sent / pda hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_plot_enc(anomalyEnc6,'2022-07-0','titlestring','xlabel',skip=100,rotate=80)\n",
    "filtered_plot_enc(anomalyEnc6,date_from='2022-07-01-00', date_to='2022-07-15-00',skip=50,rotate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_plot_enc(anomalyEnc4,date_from='2022-07-01-00', date_to='2022-07-15-00',skip=50,rotate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEnc2.anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_plot(anomalyEnc2.test,anomalyEnc2.scaler,anomalyEnc2.anomalies,anomalyEnc2.TIME_STEPS,'2022-02-','titlestring','xlabel',5,80)   \n",
    "#filtered_plot_enc(anomalyEnc2,'2022-02-','titlestring','xlabel',5,80) \n",
    "\n",
    "#get_period(anomalyEnc2.anomalies)\n",
    "anomalyEnc2.anomalies.index[0].split('-')\n",
    "\n",
    "\n",
    "print(get_index_period(anomalyEnc2.anomalies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df2 = anomalyEnc.test[anomalyEnc.TIME_STEPS:]\n",
    "_df2 = _df2[_df2.index.str.contains('2022-02-')]\n",
    "\n",
    "fig = plt.figure(figsize=(18,9))\n",
    "\n",
    "plt.plot(\n",
    "  _df2.index, \n",
    "  #scaler.inverse_transform(test[TIME_STEPS:].close), \n",
    "  anomalyEnc.scaler.inverse_transform(_df2),   \n",
    "  label='msg count'\n",
    ");\n",
    "\n",
    "ax = scatterplot(anomalyEnc.anomalies.index, _a, 'anomaly') \n",
    "\n",
    "label(ax,5,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_a=anomalyEnc.anomalies['close']\n",
    "_a = pd.DataFrame(_a)\n",
    "_a = anomalyEnc.scaler.inverse_transform(_a)\n",
    "_a = _a[:, 0]\n",
    "_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEnc.scaler.inverse_transform(anomalyEnc.test[anomalyEnc.TIME_STEPS:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEnc.test[anomalyEnc.TIME_STEPS:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = scatterplot(anomalyEnc.anomalies.index, _a, 'anomaly') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anomalyEnc = anomalyEnc2\n",
    "#plot_test(anomalyEnc2.test,anomalyEnc2.scaler,anomalyEnc2.anomalies,'titlestring', '_xlabel')\n",
    "\n",
    "filtered_plot(anomalyEnc2.test,anomalyEnc2.scaler,anomalyEnc2.anomalies,anomalyEnc2.TIME_STEPS,'2022-07-1','titlestring','xlabel',70,80) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSENDERENDPOINTID=0\n",
    "CRECEIVERENDPOINTID=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3 = widgets.Output()\n",
    "\n",
    "def models_on_change(change):\n",
    "    global anomalyEnc\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        #print(change['new'])\n",
    "        if change['new'] == 1:\n",
    "            anomalyEnc = anomalyEnc1\n",
    "        else:\n",
    "            anomalyEnc = anomalyEnc2\n",
    "\n",
    "def draw_graphs():\n",
    "    with out3:\n",
    "        clear_output()\n",
    "        sender = 0\n",
    "        #titlestring =\"endpoint (sending) : \" + str(sender) + \" ( trained: \" +  anomalyEnc.train.index[0] + \" -- \" + anomalyEnc.train.index[len(anomalyEnc.train.index)-1] + \" )\"\n",
    "        #plot_test(anomalyEnc.test,anomalyEnc.scaler,anomalyEnc.anomalies,titlestring)\n",
    "        \n",
    "        #fig = plt.figure(figsize=(12,6))\n",
    "        #plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False) \n",
    "        \n",
    "        # threshold\n",
    "        #plt.plot(anomalyEnc.test_score_df.index, anomalyEnc.test_score_df.loss, label='loss')\n",
    "        #plt.plot(anomalyEnc.test_score_df.index, anomalyEnc.test_score_df.threshold, label='threshold')\n",
    "        \n",
    "        sender = CSENDERENDPOINTID\n",
    "        receiver = CRECEIVERENDPOINTID\n",
    "        titlestring =\"endpoint \" + str(CSENDERENDPOINTID) + ' --> ' + str(CRECEIVERENDPOINTID) + \" ( trained: \" +  anomalyEnc.train.index[0] + \" -- \" + anomalyEnc.train.index[len(anomalyEnc.train.index)-1] + \" )\"\n",
    "        _xlabel = 'date: ' + anomalyEnc.test.index[0] + ' -- ' + anomalyEnc.test.index[len(anomalyEnc.test) -1]\n",
    "        plot_test(anomalyEnc.test,anomalyEnc.scaler,anomalyEnc.anomalies,titlestring, _xlabel)\n",
    "        display(anomalyEnc.anomalies)\n",
    "        \n",
    "        #plt.show(fig)\n",
    "         \n",
    "def evaluateAnomalies(threshold_X):\n",
    "    with out2:\n",
    "        anomalyEnc.evaluateAnomalies(threshold_X)\n",
    "        clear_output()\n",
    "            \n",
    "            \n",
    "def on_value_submit_threshold(change):   \n",
    "    threshold.disabled=True \n",
    "    with out3:\n",
    "        clear_output()\n",
    "    evaluateAnomalies(float(threshold.value))\n",
    "    #draw_graphs()\n",
    "    with out3:\n",
    "        clear_output()\n",
    "        display(anomalyEnc.anomalies)\n",
    "    threshold.disabled=False                \n",
    "            \n",
    "def on_value_submit_percent(change):\n",
    "    global threshold_X\n",
    "    percent.disabled=True  \n",
    "    #threshold.disabled=True \n",
    "    threshold_X = getThreshold(float(percent.value))\n",
    "    threshold.value = str(threshold_X)\n",
    "    percent.disabled=False  \n",
    "    \n",
    "percent   = widgets.Text(description = 'percent',value = '0.985', style=style, layout=layout,disabled=False)    \n",
    "percent.on_submit(on_value_submit_percent)\n",
    "\n",
    "threshold   = widgets.Text(description = 'threshold',value = '1.0', style=style, layout=layout,disabled=False)    \n",
    "threshold.on_submit(on_value_submit_threshold)\n",
    "\n",
    "models = widgets.Dropdown(description='model',options =[1,2], style=style, layout=layout,disabled=False)\n",
    "models.observe(models_on_change) \n",
    "\n",
    "anomalyEnc = anomalyEnc1\n",
    "display(models,percent,threshold,out3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anomalies(anomalyEnc,threshold):\n",
    "    anomalyEnc.evaluateAnomalies(threshold)\n",
    "    return anomalyEnc.anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getThreshold(1.0,anomalyEncC6)\n",
    "get_anomalies(anomalyEncC6,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_threshold = getThreshold(1.0,anomalyEnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_anomalies = get_anomalies(anomalyEnc,_threshold * 0.43)\n",
    "_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEnc.test\n",
    "_anomalies = anomalyEnc.anomalies\n",
    "_threshold= pd.unique(anomalyEnc.anomalies['threshold'])[0]\n",
    "_test = anomalyEnc.test[4000:5000]\n",
    "fig = plt.figure(figsize=(18,9))\n",
    "plt.plot(_test.index, _test['outcome'])    \n",
    "ax = scatterplot(_anomalies.index, _anomalies['outcome'], 'anomaly') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anomalies(anomalyEnc,test=anomalyEnc.test[4000:],expect=(4200,4400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_anomalies(anomalyEnc,test=None, expect=None, column_y='outcome',contains=None, date_from=None, date_to=None):\n",
    "    _anomalies = anomalyEnc.anomalies\n",
    "    _threshold= pd.unique(anomalyEnc.anomalies['threshold'])[0]\n",
    "    if test is None:\n",
    "        _test = anomalyEnc.test\n",
    "    else:\n",
    "        _test = test\n",
    "        \n",
    "    if contains is not None:\n",
    "        _test = _test[_test.index.str.contains(contains)]\n",
    "        #anomalies = anomalies[anomalies.index.str.contains(contains)]\n",
    "    elif date_from is not None and date_to is not None:\n",
    "        _from_index = _test.index.get_loc(date_from)\n",
    "        _to_index   = _test.index.get_loc(date_to)\n",
    "        #_df2 = _df2[_df2.index[_from_index:_to_index + 1]]\n",
    "        _test = _test.iloc[_from_index:_to_index + 1]\n",
    "       \n",
    "    else:\n",
    "        pass    \n",
    "        \n",
    "        \n",
    "    fig = plt.figure(figsize=(18,9))\n",
    "    #plt.plot(_test.index, _test[column_y])       \n",
    "    plt.plot(\n",
    "      _test.index,  \n",
    "      anomalyEnc.scaler.inverse_transform( _test),   \n",
    "      label='msg count'\n",
    "    );\n",
    "\n",
    "    _a = inverse_transform_anomalies(scaler=scaler,anomalies=_anomalies, column_y='close')\n",
    "    ax = scatterplot(_anomalies.index, _a, 'anomaly') \n",
    "    \n",
    "    #ax = scatterplot(_anomalies.index, _anomalies[column_y], 'anomaly') \n",
    "    \n",
    "    ticks = (_test.index[0], _test.index[len(_test.index) - 1])\n",
    "    plt.xticks(rotation=80,ticks=ticks)\n",
    "    \n",
    "    if expect is not None:\n",
    "        #print(_test.index.get_loc(expect[0]),_test.index.get_loc(expect[1]))\n",
    "        e1=_test.index.get_loc(expect[0])\n",
    "        e2=_test.index.get_loc(expect[1])\n",
    "        x = np.arange(e1,e2)\n",
    "        #x = np.arange(expect[0],expect[1])\n",
    "        _max = np.max(anomalyEnc.scaler.inverse_transform( _test))\n",
    "        y1 = [0]*len(x)\n",
    "        y2 = [_max]*len(x)\n",
    "        plt.fill_between(x, y1, y2, facecolor='g', alpha=.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_threshold2 = getThreshold(1.0,anomalyEnc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_threshold = getThreshold(1.0,anomalyEnc)\n",
    "_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_anomalies = get_anomalies(anomalyEnc2,0.65)\n",
    "_anomalies = get_anomalies(anomalyEnc2,_threshold2 * 0.9)\n",
    "#_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_threshold\n",
    "get_anomalies(anomalyEnc,3.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_threshold= pd.unique(anomalyEnc.anomalies['threshold'])[0]\n",
    "_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_add_anomaly(_df2):\n",
    "    hours= False\n",
    "    if len(_df2.index[0].split('-')) == 4:\n",
    "        hours = True\n",
    "    if hours == False:\n",
    "        plt.axvline(x='2022-07-12', color=\"red\")\n",
    "        #plt.axvline(x='2022-07-13', color=\"red\")\n",
    "        #plt.axvline(x='2022-09-13', color=\"red\")\n",
    "    else:    \n",
    "        plt.axvline(x='2022-07-12-10', color=\"red\")\n",
    "        plt.axvline(x='2022-07-13-15', color=\"red\")\n",
    "        #plt.axvline(x='2022-09-13-19', color=\"red\")\n",
    "        #plt.axvline(x='2022-09-13-20', color=\"red\")\n",
    "\n",
    "def plot_error(anomalyEnc):\n",
    "    fig = plt.figure(figsize=(18,9))\n",
    "    #_test = anomalyEnc.test_score_df.iloc[2050:]\n",
    "    _test = anomalyEnc.test_score_df\n",
    "    _threshold= pd.unique(anomalyEnc.anomalies['threshold'])[0]\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.plot(_test.index, _test['loss'])   \n",
    "    plt.axhline(y=_threshold, color=\"red\") \n",
    "    \n",
    "    ticks = (_test.index[0], _test.index[len(_test.index) - 1])\n",
    "    plt.xticks(rotation=80,ticks=ticks)\n",
    "    \n",
    "    plt_add_anomaly(_test)\n",
    "    \n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error(anomalyEnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error(anomalyEnc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error(anomalyEncC6)\n",
    "#anomalyEncC1.anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error(anomalyEncB6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_threshold = getThreshold(1.0,anomalyEncB6)\n",
    "get_anomalies(anomalyEncB6,0.9 * _threshold)\n",
    "\n",
    "#plot_anomalies(anomalyEncB6,column_y='close',test=anomalyEncB6.test, expect=('2022-07-12-10','2022-07-13-15'),date_from='2022-07-10-10', date_to='2022-07-14-15')\n",
    "#anomalyEncB6.test.loc['2022-07-12-10']\n",
    "#anomalyEncB6.test.index[anomalyEncB6.test.index.str.contains('2022-07-12')]\n",
    "#_pda_hour.index[_pda_hour.index.str.contains('2022-07-12')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anomalies(anomalyEncB6,column_y='close',test=anomalyEncB6.test[100:400], expect=('2022-07-12-10','2022-07-13-15'),date_from='2022-07-10-10', date_to='2022-07-14-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anomalies(anomalyEncC6,column_y='close',test=anomalyEncC6.test[100:400], expect=('2022-07-12-10','2022-07-13-15'),date_from='2022-07-10-10', date_to='2022-07-14-15')\n",
    "\n",
    "#anomalyEnc.scaler.inverse_transform(anomalyEncC6.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_graph2(test=anomalyEncC6.test, column_y='close', expect=('2022-07-12-10','2022-07-13-15'),date_from='2022-07-10-10', date_to='2022-07-14-15')\n",
    "plot_graph2(test=pda_hour, column_y='outcome', expect=('2022-07-12-10','2022-07-13-15'),date_from='2022-07-10-10', date_to='2022-07-14-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = sparkSession.read.parquet('/tmp/' + sf.iloc[len(sf)-10].file)\n",
    "_pfall = _df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pfall = _pfall[(_pfall['year']==2022) & ((_pfall['month']==7) | (_pfall['month']==6))].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pda_hour = createData_ymdh(_pfall,0)\n",
    "check(_pda_hour)\n",
    "replace_index_by_date_column(_pda_hour)\n",
    "_pda_hour = _pda_hour.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pda_hour.loc['2022-07-14-15'], pda_hour.loc['2022-07-14-15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_pda_hour[(_pda_hour['month']==7)  & (_pda_hour['day']==12)]\n",
    "plot_graph2(test=_pda_hour, column_y='outcome', expect=('2022-07-12-10','2022-07-13-15'),date_from='2022-07-10-10', date_to='2022-07-14-15')\n",
    "#_pda_hour.index.get_loc('2022-07-12-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBarplot(md=None,fx=24,fy=12,fontscale=3.0,title=\"\",expect=None) :\n",
    "    sns.set(style='whitegrid', palette='muted', font_scale=fontscale)\n",
    "    plt.figure(figsize=(fx,fy))\n",
    "    plt.title(title)\n",
    "    ax = sns.barplot(x=md.index, y=md['close'], data=md)\n",
    "    #ax = sns.barplot(x=md['date'], y=md['outcome'], data=md)\n",
    "    #plt.setp( ax.xaxis.get_majorticklabels(), rotation=75 )\n",
    "    _test=md\n",
    "    #ticks = (_test.index[0], _test.index[len(_test.index) - 1])\n",
    "    #plt.xticks(range(0,len(ticks)), ticks, rotation=80)\n",
    "    label(ax,20,80)\n",
    "    \n",
    "    #plt.xticks(range(0,len(_test.index)), _test.index)\n",
    "    #plt.xticks(rotation=80,ticks=ticks)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if expect is not None:\n",
    "        #print(_test.index.get_loc(expect[0]),_test.index.get_loc(expect[1]))\n",
    "        e1=_test.index.get_loc(expect[0])\n",
    "        e2=_test.index.get_loc(expect[1])\n",
    "        x = np.arange(e1,e2)\n",
    "        #x = np.arange(expect[0],expect[1])\n",
    "        _max = np.max(anomalyEnc.scaler.inverse_transform( _test))\n",
    "        y1 = [0]*len(x)\n",
    "        y2 = [_max]*len(x)\n",
    "        plt.fill_between(x, y1, y2, facecolor='g', alpha=.3)\n",
    "    \n",
    "    plt.show()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anomalyEncC6.test[100:400].index\n",
    "createBarplot(anomalyEncC6.test[100:400],24,12,3.0,expect=('2022-07-12-10','2022-07-13-15'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_numsenders = str(len(senders))\n",
    "md = createData_ym(pfall0,0)\n",
    "ax=createBarplot(md,24,12,3.0,title=\"number messages sent by endpoint \"  + str(pd.unique(pfall0['CSENDERENDPOINTID'])[0]) + ' (' + _numsenders + ' sending endpoints)' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_transform_anomalies(scaler=anomalyEncC6.scaler,anomalies=anomalyEncC6.anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEncC6.test.loc['2022-07-12-06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pda_hour[(pda_hour['year'] == 2022) & (pda_hour['month'] == 7) & (pda_hour['day'] == 12)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEncC6.test[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_anomalies(anomalyEncC6,1.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(anomalyEnc2.anomalies['threshold'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEnc.test\n",
    "\n",
    "fig = plt.figure(figsize=(18,9))\n",
    "_test = anomalyEnc2.test.iloc[2100:]\n",
    "plt.plot(_test.index, _test['close'])    \n",
    "ax = scatterplot(_anomalies.index, _anomalies['close'], 'anomaly') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_a = _anomalies['outcome']\n",
    "_a = pd.DataFrame(_a)\n",
    "_a = scaler.inverse_transform(_a)\n",
    "_a = _a[:, 0]\n",
    "_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_thresholdC1 = getThreshold(1.0,anomalyEncC1)\n",
    "_thresholdC2 = getThreshold(1.0,anomalyEncC2)\n",
    "_thresholdC3 = getThreshold(1.0,anomalyEncC3)\n",
    "_thresholdC4 = getThreshold(1.0,anomalyEncC4)\n",
    "_thresholdC5 = getThreshold(1.0,anomalyEncC5)\n",
    "_thresholdC6 = getThreshold(1.0,anomalyEncC6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_anomalies(anomalyEncC1,_thresholdC1 * 0.8)\n",
    "get_anomalies(anomalyEncC2,_thresholdC2 * 0.8)\n",
    "get_anomalies(anomalyEncC3,_thresholdC3 * 0.8)\n",
    "get_anomalies(anomalyEncC4,_thresholdC4 * 0.8)\n",
    "get_anomalies(anomalyEncC5,_thresholdC5 * 0.8)\n",
    "get_anomalies(anomalyEncC6,_thresholdC6 * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_threshold7 = getThreshold(1.0,anomalyEnc7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_anomalies(anomalyEnc7,_threshold7 * 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_anomalies(anomalyEnc3,_threshold3 * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEnc4.anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_anomalies(anomalyEnc4,_threshold4 * 0.7)\n",
    "filtered_plot_enc(anomalyEnc4,'2022-07-','titlestring','xlabel',100,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_plot_enc(anomalyEnc6,'2022-07-','titlestring','xlabel',100,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_threshold3 = getThreshold(1.0,anomalyEnc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_anomalies(anomalyEnc3,_threshold3 * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_plot(anomalyEnc3.test,anomalyEnc3.scaler,anomalyEnc3.anomalies,anomalyEnc3.TIME_STEPS,'2022-07-1','titlestring','xlabel',70,80) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test(anomalyEnc,anomalies,titlestring,xlabel):\n",
    "\n",
    "    fig = plt.figure(figsize=(18,9))\n",
    "    \n",
    "    _a=anomalies['close']\n",
    "    _a = pd.DataFrame(_a)\n",
    "    _a = anomalyEnc.scaler.inverse_transform(_a)\n",
    "    _a = _a[:, 0]\n",
    "    #print(_a,type(_a),_a[0],len(_a),len(_a[:, 0]))\n",
    "    ax = scatterplot(anomalies.index, _a, 'anomaly') \n",
    "    \n",
    "    ax.set_xlabel(xlabel)\n",
    "    plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False) \n",
    "    plt.xticks(rotation=25)\n",
    "    plt.legend();\n",
    "\n",
    "    label(ax,5,80)\n",
    "    plt.title(titlestring)\n",
    "    plt.show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = get_anomalies(anomalyEnc3,_threshold3 * 0.9)\n",
    "plot_test(anomalyEnc3, anomalies, '','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_plot(anomalyEnc3.test,anomalyEnc3.scaler,anomalyEnc3.anomalies,anomalyEnc3.TIME_STEPS,'2022-07-1','titlestring','xlabel') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test1(anomalies,test,scaler,titlestring,xlabel):\n",
    "\n",
    "    fig = plt.figure(figsize=(18,9))\n",
    "    \n",
    "    plt.plot(\n",
    "      #test[anomalyEnc.TIME_STEPS:].index, \n",
    "      test.index,  \n",
    "      #scaler.inverse_transform(test[TIME_STEPS:].close), \n",
    "      #scaler.inverse_transform(test[anomalyEnc.TIME_STEPS:]),  \n",
    "      scaler.inverse_transform(test),  \n",
    "      label='msg count'\n",
    "    );\n",
    "\n",
    "    \n",
    "    _a=anomalies['close']\n",
    "    _a = pd.DataFrame(_a)\n",
    "    _a = anomalyEnc.scaler.inverse_transform(_a)\n",
    "    _a = _a[:, 0]\n",
    "    #print(_a,type(_a),_a[0],len(_a),len(_a[:, 0]))\n",
    "    ax = scatterplot(anomalies.index, _a, 'anomaly') \n",
    "    \n",
    "    \n",
    "    #ax.set_xlabel(xlabel)\n",
    "    plt.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=False) \n",
    "    plt.xticks(rotation=25)\n",
    "    plt.legend();\n",
    "\n",
    "    #label(ax,5,80)\n",
    "    plt.title(titlestring)\n",
    "    plt.show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = anomalyEnc3.test\n",
    "_df = _df[_df.index.str.contains('2022-07-1')]\n",
    "plot_test1(anomalies,_df,anomalyEnc3.scaler,'','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "listi = list(anomalyEnc3.test.index)\n",
    "sub = '2022-07-1'\n",
    "\n",
    "print (\"\\n\".join(s for s in listi if sub in s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEnc3.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_anomalies(anomalyEnc1,_threshold1 * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listi = list(anomalyEnc2.anomalies.index)\n",
    "sub = '2022-07-1'\n",
    "\n",
    "print (\"\\n\".join(s for s in listi if sub in s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getThreshold(0.9),getThreshold(0.8),getThreshold(0.7),getThreshold(0.6),getThreshold(0.5)\n",
    "_thresholds=(5.723571592241854,5.151214433017669,4.578857273793484,4.006500114569298,3.4341429553451124,2.861785796120927)\n",
    "#getThreshold(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_thresholds[0] - _thresholds[1], _thresholds[2] - _thresholds[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent.disabled=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs=list(anomalyEnc.anomalies.index)\n",
    "[s for s in xs if \"2022\" in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSENDERENDPOINTID=0\n",
    "CRECEIVERENDPOINTID=0\n",
    "print(TimeRange(dataframe=pfall).__dict__)\n",
    "md = createData_ym(pfall0,0)\n",
    "ax=createBarplot(md,24,12,3.0,title=\"number messages \" +  \"endpoint \" + str(CSENDERENDPOINTID) + ' --> ' + str(CRECEIVERENDPOINTID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display (year_hbox,month_hbox,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent   = widgets.Text(description = 'percent',value = '0.985', style=style, layout=layout,disabled=False)    \n",
    "percent.on_submit(on_value_submit_percent)\n",
    "\n",
    "models = widgets.Dropdown(description='model',options =[1,2], style=style, layout=layout,disabled=False)\n",
    "models.observe(models_on_change) \n",
    "\n",
    "anomalyEnc = anomalyEnc1\n",
    "display(models,percent,threshold,out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(anomalyEnc.anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'2022-10-02-14' in anomalyEnc.anomalies.index\n",
    "\n",
    "listi = list(anomalyEnc2.anomalies.index)\n",
    "sub = '2022-07-1'\n",
    "\n",
    "print (\"\\n\".join(s for s in listi if sub in s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messagetracking der Service-Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfall0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_numsenders = str(len(senders))\n",
    "md = createData_ym(pfall0,0)\n",
    "ax=createBarplot(md,24,12,3.0,title=\"number messages sent by endpoint \"  + str(pd.unique(pfall0['CSENDERENDPOINTID'])[0]) + ' (' + _numsenders + ' sending endpoints)' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Problembeschreibungen / Erwartungsmonitoring\n",
    "\n",
    "- am 12.07.2022 wurde ein BIS Release installiert dass zur Verzögerung vieler Nachrichten geführt hat.\n",
    "Die letzten Nachrichten wurden am Folgetag um ca. 15:00 Uhr CET verarbeitet.\n",
    "Es sollten also deutliche Anomalien zwischen 12.07.2022 (10:00 Uhr) bis 13.07.2022 (15:00 Uhr) zu sehen sein.\n",
    "\n",
    "\n",
    "- 13.09.2022 19:00 Uhr / 20:00 Uhr UTC: Massive Last, Anflutung des Systems, vor allem im zweiten Intervall.\n",
    "Durchlaufzeiten waren deutlich erhöht. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Anomalieerkennung und Erwartungsmonitoring (messages sent / hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#anomalyEnc6 = train_model(dataframe=pda_hour, time_steps=24, year=2022,month=6)\n",
    "filtered_plot_enc(anomalyEnc6,date_from='2022-07-01-00', date_to='2022-07-15-00',skip=50,rotate=80,titlestring= 'trained: ' + str(get_trained_period(anomalyEnc6)) + ' , time_steps=24')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomalieerkennung und Erwartungsmonitoring (Durchlaufszeit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_plot_enc2(anomalyEnc5,date_from='2022-07-01-00', date_to='2022-07-15-00',skip=50,rotate=80,titlestring= 'trained: ' + str(get_trained_period(anomalyEnc6)) + ' , time_steps=24', ylabel='CMESSAGETAT2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyEnc5.test.index.get_loc( '2022-09-01-00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_num_anomalies = len(get_anomalies(anomalyEnc5,_threshold5 * 0.8))\n",
    "filtered_plot_enc2(anomalyEnc5,date_from='2022-09-15-00', date_to='2022-10-04-00',skip=50,rotate=80,titlestring= 'trained: ' + str(get_trained_period(anomalyEnc6)) + ' , time_steps=24' + ', #anomalies: ' + str(_num_anomalies), ylabel='CMESSAGETAT2',annotations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_num_anomalies = len(get_anomalies(anomalyEnc5,_threshold5 * 0.77))\n",
    "filtered_plot_enc2(anomalyEnc5,date_from='2022-09-15-00', date_to='2022-10-04-00',skip=50,rotate=80,titlestring= 'trained: ' + str(get_trained_period(anomalyEnc6)) + ' , time_steps=24' + ', #anomalies: ' + str(_num_anomalies), ylabel='CMESSAGETAT2',annotations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_num_anomalies = len(get_anomalies(anomalyEnc5,_threshold5 * 0.75))\n",
    "filtered_plot_enc2(anomalyEnc5,date_from='2022-08-17-00', date_to='2022-10-04-00',skip=50,rotate=80,titlestring= 'trained: ' + str(get_trained_period(anomalyEnc6)) + ' , time_steps=24' + ', #anomalies: ' + str(_num_anomalies), ylabel='CMESSAGETAT2',annotations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_anomalies(anomalyEnc5,_threshold5 * 0.77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial Ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = \"http://172.30.12.56:3128\" \n",
    "os.environ['https_proxy'] = \"https://172.30.12.56:3128\"  \n",
    "#!git clone https://github.com/ReNom-dev-team/ReNom.git\n",
    "!pip install renom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ReNom-dev-team/ReNom.git\n",
    "!pip install -r requirements.txt\n",
    "!cd ReNom\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import renom as rm\n",
    "from renom.optimizer import Adam\n",
    "from renom.cuda import set_cuda_active\n",
    "set_cuda_active(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.renom.jp/notebooks/tutorial/time_series/lstm-anomalydetection/notebook.html\n",
    "\n",
    "# standardize\n",
    "scaler = StandardScaler()\n",
    "std_ecg = scaler.fit_transform(ecg)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('ECG\\'s value')\n",
    "plt.plot(np.arange(5000), std_ecg[:5000], color='b')\n",
    "plt.ylim(-3, 3)\n",
    "x = np.arange(4200,4400)\n",
    "y1 = [-3]*len(x)\n",
    "y2 = [3]*len(x)\n",
    "plt.fill_between(x, y1, y2, facecolor='g', alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_cycle = std_ecg[5000:]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"training data\")\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('ECG\\'s value')\n",
    "plt.plot(np.arange(5000,8000), normal_cycle[:3000], color='b')# stop plot at 8000 times for friendly visual\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data of the \"look_back\" length from time-series, \"ts\"\n",
    "# and the next \"pred_length\" values as labels\n",
    "def create_subseq(ts, look_back, pred_length):\n",
    "    sub_seq, next_values = [], []\n",
    "    for i in range(len(ts)-look_back-pred_length):  \n",
    "        sub_seq.append(ts[i:i+look_back])\n",
    "        next_values.append(ts[i+look_back:i+look_back+pred_length].T[0])\n",
    "    return sub_seq, next_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 10\n",
    "pred_length = 3\n",
    "\n",
    "sub_seq, next_values = create_subseq(normal_cycle, look_back, pred_length)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    sub_seq, next_values, test_size=0.2)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "train_size = X_train.shape[0]\n",
    "test_size = X_test.shape[0]\n",
    "print('train size:{}, test size:{}'.format(train_size, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "model = rm.Sequential([\n",
    "    rm.Lstm(35),\n",
    "    rm.Relu(),\n",
    "    rm.Lstm(35),\n",
    "    rm.Relu(),\n",
    "    rm.Dense(pred_length)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = \"http://172.30.12.56:3128\" \n",
    "os.environ['https_proxy'] = \"https://172.30.12.56:3128\"  \n",
    "!pip3 install --trusted-host pypi.org --trusted-host files.pythonhosted.org tensorflow==2.4.1\n",
    "!pip3 install --trusted-host pypi.org --trusted-host files.pythonhosted.org numpy==1.18.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "import os\n",
    "os.environ['http_proxy'] = \"http://172.30.12.56:3128\" \n",
    "os.environ['https_proxy'] = \"https://172.30.12.56:3128\"  \n",
    "import ssl\n",
    "import certifi\n",
    "import ssl\n",
    "import urllib\n",
    "context = ssl.create_default_context(cafile=certifi.where())\n",
    "result = urllib.request.urlopen('https://www.example.com', context=context)\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# For Google Colab:\n",
    "!pip3 install --trusted-host pypi.org --trusted-host files.pythonhosted.org kats\n",
    "    \n",
    "#!wget https://raw.githubusercontent.com/facebookresearch/Kats/main/kats/data/air_passengers.csv\n",
    "#!wget https://raw.githubusercontent.com/facebookresearch/Kats/main/kats/data/multi_ts.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from kats.consts import TimeSeriesData"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
