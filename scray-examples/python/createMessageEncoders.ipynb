{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoder files for categorical columns and store the files\n",
    "# status: needs to be cleaned up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "import dfBasics\n",
    "import common\n",
    "import encoder\n",
    "import pfAdapt\n",
    "import charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkSession = dfBasics.getSparkSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = sparkSession.read.parquet('hdfs://172.30.17.145:8020/sla_sql_data/*/*').select(columns).dropDuplicates() \n",
    "df = sparkSession.read.parquet('hdfs://172.30.17.145:8020/sla_sql_data/*/*').dropDuplicates() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.limit(1).toPandas().columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutColumns = ['CGLOBALMESSAGEID','CSTARTTIME', 'CENDTIME','CINBOUNDSIZE', 'CSLATAT', 'CMESSAGETAT2', 'CSLADELIVERYTIME']\n",
    "columns = columns[~columns.isin(withoutColumns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSTATUS\n",
      "['COMPONENT_ERROR' 'COMPONENT_ERROR_CONTENTEXTRACTOR'\n",
      " 'CONFIGURATION_ERROR' 'DATA_ERROR' 'DELETED' 'ECHO-ERROR' 'ERROR'\n",
      " 'EXPIRED' 'FAILED' 'MDN_ERROR' 'MESSAGE_QUEUED' 'PENDING'\n",
      " 'READY_FOR_DOWNLOAD' 'RECALLED' 'SUCCESS' 'SUCCESS_DOWNLOADED'\n",
      " 'SUCCESS_POLLQUEUE' 'THREAT_DETECTED' 'TORESEND' 'WARNING']\n",
      "CSERVICE\n",
      "['COM.Routing.SupplierPortal' 'Content-Based Routing' 'EchoService' 'IDS'\n",
      " 'InvoicePortal' 'MAKO_BE_ROUTER' 'MaKo' 'Metadata-Based Routing' 'None'\n",
      " 'PEPPOL' 'SFID Metadata-Based Routing' 'SSP' 'VAN Routing' 'VAT.UK']\n",
      "CSLABILLINGMONTH\n",
      "['2019-10' '2019-11' '2019-12' '2020-01' '2020-02' '2020-03' '2020-04'\n",
      " '2020-05' '2020-06' '2020-07' '2020-08' '2020-09' '2020-10' '2020-11'\n",
      " '2020-12' '2021-01' '2021-02' '2021-03' '2021-04' '2021-05' '2021-06'\n",
      " '2021-07' '2021-08' '2021-09' '2021-10' '2021-11' '2021-12' '2022-01'\n",
      " '2022-02' '2022-03' '2022-04' '2022-05' '2022-06' '2022-07' '2022-08'\n",
      " '2022-09' '2022-10' '2022-11' '2022-12' '2023-01' '2023-02' '2023-03'\n",
      " '2023-04' '2023-05' '2023-06' '2023-07' '2023-08' '2023-09' '2023-10'\n",
      " '2023-11' 'None']\n",
      "CSENDERPROTOCOL\n",
      "['AS2' 'AS4' 'B2BDIR' 'HTTP' 'MAIL' 'None' 'OFTP2' 'REST' 'SFTP' 'SLMP'\n",
      " 'SLMP_PLUS_MS']\n",
      "CSENDERENDPOINTID\n",
      "['000b4e02-7f43-11ec-ae40-78d9ac1e124d'\n",
      " '0014de30-f8ec-11eb-9933-02daac1e124d'\n",
      " '00171070-9207-11eb-9829-4c38ac1e124c' ...\n",
      " 'ffe5afd0-ecc7-11e8-a40c-5396ac1b495c'\n",
      " 'ffef96a0-e427-11e9-ac2e-4c78ac1b495c'\n",
      " 'fff8bb00-a213-11e9-a189-ddafac1b495c']\n",
      "CRECEIVERPROTOCOL\n",
      "['AS2' 'AS4' 'HTTP' 'MAIL' 'N/A' 'None' 'OFTP2' 'PEPPOL' 'QUEUE' 'REST'\n",
      " 'SFTP' 'SLMP' 'SLMPPOLL' 'SLMP_PLUS_MS' 'unknown']\n",
      "CRECEIVERENDPOINTID\n",
      "['000b4e02-7f43-11ec-ae40-78d9ac1e124d'\n",
      " '0014de30-f8ec-11eb-9933-02daac1e124d'\n",
      " '00171070-9207-11eb-9829-4c38ac1e124c' ...\n",
      " 'ffe5afd0-ecc7-11e8-a40c-5396ac1b495c'\n",
      " 'fff20390-7cce-11eb-8926-4191ac1e124c'\n",
      " 'fff8bb00-a213-11e9-a189-ddafac1b495c']\n"
     ]
    }
   ],
   "source": [
    "for column in columns:\n",
    "    print(column)\n",
    "    df4 = df.select(column).dropDuplicates().toPandas() \n",
    "    df4[column] = df4[column].astype(str)\n",
    "    encoder.createEncoders(df4,[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge CSENDERENDPOINTID and CRECEIVERENDPOINTID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv CSENDERENDPOINTID.npy single_CSENDERENDPOINTID.npy \n",
    "!mv CRECEIVERENDPOINTID.npy single_CRECEIVERENDPOINTID.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'CSENDERENDPOINTID'\n",
    "df4_1 = df.select(column).dropDuplicates().toPandas()\n",
    "column = 'CRECEIVERENDPOINTID'\n",
    "df4_2 = df.select(column).dropDuplicates().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = list(set(list(df4_1['CSENDERENDPOINTID']) + list(df4_2['CRECEIVERENDPOINTID'])))\n",
    "df4 = pd.DataFrame(columns=['CSENDERENDPOINTID'])\n",
    "df4['CSENDERENDPOINTID'] = endpoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000b4e02-7f43-11ec-ae40-78d9ac1e124d'\n",
      " '0014de30-f8ec-11eb-9933-02daac1e124d'\n",
      " '00171070-9207-11eb-9829-4c38ac1e124c' ...\n",
      " 'fff20390-7cce-11eb-8926-4191ac1e124c'\n",
      " 'fff8bb00-a213-11e9-a189-ddafac1b495c' None]\n"
     ]
    }
   ],
   "source": [
    "encoder.createEncoders(df4,['CSENDERENDPOINTID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp CSENDERENDPOINTID.npy CRECEIVERENDPOINTID.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### move npy files in versioned folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p v00003/npy\n",
    "!mv *.npy v00003/npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot move 'v00003' to '/home/jovyan/work/share/sla/v00003': Permission denied\n"
     ]
    }
   ],
   "source": [
    "!mv v00003 /home/jovyan/work/share/sla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# append new encoding classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sparkSession.read.parquet('hdfs://172.30.17.145:8020/user/admin/sla/v00001/v00002/encoded/all/*/*').dropDuplicates() \n",
    "columns = df.limit(1).toPandas().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutColumns = ['CGLOBALMESSAGEID','CSTARTTIME', 'CENDTIME','CINBOUNDSIZE', 'CSLATAT', 'CMESSAGETAT2', 'CSLADELIVERYTIME','year', 'month', 'day', 'hour', 'minute', 'error']\n",
    "columns = columns[~columns.isin(withoutColumns)]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org  = sparkSession.read.parquet('hdfs://172.30.17.145:8020/sla_sql_data/*/*').dropDuplicates() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'CSERVICE'\n",
    "df4 = df_org.select(column).dropDuplicates().toPandas() \n",
    "df4[column] = df4[column].astype(str)\n",
    "df4 = df4[df4[column] != 'None']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy= share_directory + 'sla/' + version_sla + '/npy'\n",
    "_encoder = TolerantLabelEncoder(ignore_unknown=True)\n",
    "_encoder.classes_ = np.load(npy + '/' + column + '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.append(_encoder.diff(list(df4[column])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_version_sla = 'v00002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_directory = home_directory + 'output/' + new_version_sla + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns:\n",
    "    print(column)\n",
    "    df4 = df_org.select(column).dropDuplicates().toPandas() \n",
    "    df4[column] = df4[column].astype(str)\n",
    "    df4 = df4[df4[column] != 'None']\n",
    "    \n",
    "    npy= share_directory + 'sla/' + version_sla + '/npy'\n",
    "    _encoder = TolerantLabelEncoder(ignore_unknown=True)\n",
    "    _encoder.classes_ = np.load(npy + '/' + column + '.npy')\n",
    "    \n",
    "    _encoder.append(_encoder.diff(list(df4[column])))\n",
    "    np.save(new_directory + column + '.npy', _encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#npy= share_directory + 'sla/' + version_sla + '/npy'\n",
    "column = columns[5]\n",
    "npy=  new_directory \n",
    "_encoder = TolerantLabelEncoder(ignore_unknown=True)\n",
    "#_encoder.classes_ = np.load(npy + '/' + column + '.npy')\n",
    "_encoder.classes_ = np.load(npy + column + '.npy')\n",
    "_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run encoder.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "\n",
    "class TolerantLabelEncoder(LabelEncoder):\n",
    "    def __init__(self, ignore_unknown=False,\n",
    "                       unknown_original_value='unknown', \n",
    "                       unknown_encoded_value=-1):\n",
    "        self.ignore_unknown = ignore_unknown\n",
    "        self.unknown_original_value = unknown_original_value\n",
    "        self.unknown_encoded_value = unknown_encoded_value\n",
    "\n",
    "    def transform(self, y):\n",
    "        check_is_fitted(self, 'classes_')\n",
    "        y = column_or_1d(y, warn=True)\n",
    "\n",
    "        indices = np.isin(y, self.classes_)\n",
    "        if not self.ignore_unknown and not np.all(indices):\n",
    "            raise ValueError(\"y contains new labels: %s\" \n",
    "                                         % str(np.setdiff1d(y, self.classes_)))\n",
    "\n",
    "        y_transformed = np.searchsorted(self.classes_, y)\n",
    "        y_transformed[~indices]=self.unknown_encoded_value\n",
    "        return y_transformed\n",
    "\n",
    "    # for appended versions\n",
    "    def transform_version(self, y):\n",
    "        results = self.transform(y)\n",
    "        index = np.where(results == -1)[0]\n",
    "        with_prefix = ['zzzz_0001_' + y[i] for i in index]\n",
    "        results_with_prefix = self.transform(with_prefix)\n",
    "        for i,r in enumerate(results_with_prefix):\n",
    "            results[index[i]] = r\n",
    "        return results    \n",
    "    \n",
    "    def inverse_transform(self, y):\n",
    "        check_is_fitted(self, 'classes_')\n",
    "\n",
    "        labels = np.arange(len(self.classes_))\n",
    "        indices = np.isin(y, labels)\n",
    "        if not self.ignore_unknown and not np.all(indices):\n",
    "            raise ValueError(\"y contains new labels: %s\" \n",
    "                                         % str(np.setdiff1d(y, self.classes_)))\n",
    "\n",
    "        y_transformed = np.asarray(self.classes_[y], dtype=object)\n",
    "        y_transformed[~indices]=self.unknown_original_value\n",
    "        return y_transformed\n",
    "\n",
    "    # problem with None\n",
    "    def dict(self):\n",
    "        return dict(zip(self.classes_, self.transform(self.classes_)))\n",
    "    \n",
    "    def diff(self,values):\n",
    "        _encoded = list(_encoder.classes_)\n",
    "        try:\n",
    "            _encoded.remove(None)\n",
    "        except Exception as exception:\n",
    "            pass\n",
    "        return list(set(values) - set(_encoded))\n",
    "    \n",
    "    def append(self,values, version='0001'):\n",
    "        self.classes_ = np.append(self.classes_, ['zzzz' + '_' + version + '_' + s  for s in list(np.sort(list(values)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dfBasics\n",
    "import pandas as pd\n",
    "\n",
    "version_sla = 'v00001'\n",
    "version     = version_sla + '/v00000'\n",
    "\n",
    "home_directory  =  '/home/jovyan/work/'\n",
    "share_directory =  '/home/jovyan/work/share/'\n",
    "#share_directory =  '/home/jovyan/share/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init encoders (run only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - run this paragraph only once !\n",
    "# - if you get an 'allow_pickle' error you need Kernel/restart kernel\n",
    "\n",
    "import encoder\n",
    "import numpy as np\n",
    "\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "# restore np.load for future normal usage\n",
    "#np.load = np_load_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encode value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(value,column=None, npy= share_directory + 'sla/' + version_sla + '/npy'):\n",
    "    _encoder = encoder.TolerantLabelEncoder(ignore_unknown=True)\n",
    "    _encoder.classes_ = np.load(npy + '/' + column + '.npy')\n",
    "    return int( _encoder.transform([value])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decode value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(value,column=None, npy= share_directory + 'sla/' + version_sla + '/npy'):\n",
    "    _encoder = encoder.TolerantLabelEncoder(ignore_unknown=True)\n",
    "    _encoder.classes_ = np.load(npy + '/' + column + '.npy')\n",
    "    if type(value) == int:\n",
    "        return str(_encoder.inverse_transform(value))  \n",
    "    elif type(value) == list:\n",
    "        return [str(_encoder.inverse_transform(v)) for v in value]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_transform([6,5],column='CSERVICE')\n",
    "inverse_transform(6, 'CSTATUS')\n",
    "#inverse_transform(list(pd.unique(pfall['CSTATUS'])),'CSTATUS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# replace -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# check for rows with -1\n",
    "year = 2023\n",
    "month = 5\n",
    "df2 = df.where(f.col(\"year\").isin([year])).where(f.col(\"month\").isin([month]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df3 = df2.where((f.col('CSTATUS')==-1) | (f.col('CSERVICE')==-1) | (f.col('CSENDERENDPOINTID')==-1) | (f.col('CSENDERPROTOCOL')==-1)| (f.col('CRECEIVERPROTOCOL')==-1) | (f.col('CRECEIVERENDPOINTID')==-1))\n",
    "ids =  np.array(df3.select('CGLOBALMESSAGEID').drop_duplicates().collect())     \n",
    "ids = [i[0] for i in ids.tolist()]\n",
    "not_ids = np.array(df2.select('CGLOBALMESSAGEID').filter(df2.CGLOBALMESSAGEID.isin(ids) == False).drop_duplicates().collect())  \n",
    "not_ids = [i[0] for i in not_ids.tolist()]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_test = df_org.where(f.col(\"CGLOBALMESSAGEID\").isin([ids[0]]))\n",
    "result = process(dataframe=df_test, encoders=encoders, columns=columns)\n",
    "result.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(year,month,columns):\n",
    "    df4 = df3.where(f.col(\"year\").isin([year])).where(f.col(\"month\").isin([month]))\n",
    "    df4.write.mode('overwrite').parquet('/home/jovyan/work/output/sla_enc_all_v00001_v00002_' + str(year) + '_' + str(month) + '.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for rows with -1\n",
    "year = 2023\n",
    "month = 5\n",
    "df2 = df.where(f.col(\"year\").isin([year])).where(f.col(\"month\").isin([month]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(df2.where((f.col('CSTATUS')==-1) | (f.col('CSERVICE')==-1) | (f.col('CSENDERENDPOINTID')==-1) | (f.col('CSENDERPROTOCOL')==-1)| (f.col('CRECEIVERPROTOCOL')==-1) | (f.col('CRECEIVERENDPOINTID')==-1)).select('CGLOBALMESSAGEID').toPandas()['CGLOBALMESSAGEID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run functions_encode.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = df2\n",
    "df3 = dataframe.where(f.col(\"CGLOBALMESSAGEID\").isin([ids[0]]))\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = df_org\n",
    "selected_columns = ['CGLOBALMESSAGEID',  'CSTARTTIME', 'CENDTIME', 'CSTATUS', 'CSERVICE', 'CSENDERENDPOINTID', 'CSENDERPROTOCOL', 'CINBOUNDSIZE', 'CRECEIVERPROTOCOL', 'CRECEIVERENDPOINTID', 'CSLATAT', 'CMESSAGETAT2', 'CSLADELIVERYTIME']\n",
    "#df3 = dataframe.where(f.col(\"CGLOBALMESSAGEID\").isin([ids[0]]))\n",
    "df3 = dataframe.where(f.col(\"CGLOBALMESSAGEID\") == ids[0]).select(selected_columns).dropDuplicates() \n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_org.where(f.col(\"CRECEIVERPROTOCOL\") == 'N/A')\n",
    "test.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load encoders\n",
    "\n",
    "#npy='/home/jovyan/work/npy'\n",
    "npy=  new_directory\n",
    "encoders = {}\n",
    "for column in columns:\n",
    "    #_encoder = encoder.TolerantLabelEncoder(ignore_unknown=True)\n",
    "    _encoder = TolerantLabelEncoder(ignore_unknown=True)\n",
    "    _encoder.classes_ = np.load(npy + '/' + column + '.npy')\n",
    "    encoders[column] = _encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import encoder\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def transform(value):\n",
    "    return int( _encoder.transform([value])[0])\n",
    "\n",
    "column = 'CSENDERPROTOCOL'\n",
    "_encoder = encoders[column]\n",
    "dataframe = df3\n",
    "\n",
    "udf_transform = udf(lambda z: transform(z), StringType())\n",
    "df4 = dataframe.withColumn(column, udf_transform(col(column)).cast(\"Integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix replace prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'CRECEIVERENDPOINTID'\n",
    "_encoder = encoders[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_encoder.classes_.tolist()\n",
    "_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_prefix(s):\n",
    "    version = '0001'\n",
    "    if s.startswith('____0001_'):\n",
    "        return 'zzzz' + '_' + version + '_' + s.split('____0001_')[1]\n",
    "    else:\n",
    "        return s\n",
    "    \n",
    "_encoder.classes_ = np.sort(np.array([fix_prefix(s) for s in _encoder.classes_.tolist()]).astype(object))   \n",
    "encoders[column] = _encoder\n",
    "\n",
    "new_directory = home_directory + 'output/' + new_version_sla + '/'\n",
    "np.save(new_directory + column + '.npy', _encoder.classes_)\n",
    "\n",
    "_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix None Encoder Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'CSENDERENDPOINTID'\n",
    "_encoder = encoders[column]\n",
    "#np.sort(_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = _encoder.classes_\n",
    "len(classes)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for None\n",
    "index = np.where(_encoder.classes_ == None)[0][0]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.inverse_transform([9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.transform(['zzzz_0001_fe99e900-34c3-11ed-91f0-6348ac1e124d_part'])\n",
    "#_encoder.transform(['____0001_fe99e900-34c3-11ed-91f0-6348ac1e124d_part'])    \n",
    "_encoder.transform(['00171070-9207-11eb-9829-4c38ac1e124c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.inverse_transform([6146])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=['zzzz_0001_fe99e900-34c3-11ed-91f0-6348ac1e124d_part','fekkkk900-34c3-11ed-91f0-6348ac1e124d_part','fe99e900-34c3-11ed-91f0-6348ac1e124d_part','ffe4d710-d9ec-11ed-9913-0514ac1e124d']\n",
    "results = np.isin(y, _encoder.classes_)\n",
    "#np.where(results == False)[0][0]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.transform_version(['ffe4d710-d9ec-11ed-9913-0514ac1e124d'])\n",
    "#_encoder.transform_version(['fe99e900-34c3-11ed-91f0-6348ac1e124d_part'])\n",
    "_encoder.transform_version(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.transform(['____0001_ffe4d710-d9ec-11ed-9913-0514ac1e124d'])\n",
    "#_encoder.transform(['____0001_fe99e900-34c3-11ed-91f0-6348ac1e124d_part'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = _encoder.transform(y)\n",
    "index = np.where(results == -1)[0]\n",
    "with_prefix = ['____0001_' + y[i] for i in index]\n",
    "results_with_prefix = _encoder.transform(with_prefix)\n",
    "for i,r in enumerate(results_with_prefix):\n",
    "    results[index[i]] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_with_prefix\n",
    "with_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.transform(with_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.inverse_transform(6148)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.transform(['____0001_ffe4d710-d9ec-11ed-9913-0514ac1e124d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index,results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.transform_version(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ['____0001_ffe4d710-d9ec-11ed-9913-0514ac1e124d']\n",
    "y = column_or_1d(y, warn=True)\n",
    "indices = np.isin(y, _encoder.classes_)\n",
    "y_transformed = np.searchsorted(_encoder.classes_, y)\n",
    "y_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.classes_[3450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.classes_ = np.append(_encoder.classes_,['zzzz_000b4e02-7f43-11ec-ae40-78d9ac1e124d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.transform(['ZZZZfgsf4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted = np.sort(_encoder.classes_)\n",
    "len(sorted)\n",
    "np.where(sorted == 'zzzz_000b4e02-7f43-11ec-ae40-78d9ac1e124d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.transform(['zzzz_000b4e02-7f43-11ec-ae40-78d9ac1e124d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted[3453]\n",
    "type(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_is_fitted(self, 'classes_')\n",
    "        y = column_or_1d(y, warn=True)\n",
    "\n",
    "        indices = np.isin(y, self.classes_)\n",
    "        if not self.ignore_unknown and not np.all(indices):\n",
    "            raise ValueError(\"y contains new labels: %s\" \n",
    "                                         % str(np.setdiff1d(y, self.classes_)))\n",
    "\n",
    "        y_transformed = np.searchsorted(self.classes_, y)\n",
    "        y_transformed[~indices]=self.unknown_encoded_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.transform(['PEPPOL'])\n",
    "_encoder.transform(['SFID Metadata-Based Routing'])\n",
    "_encoder.transform(['VAT.UK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df.select([column]).drop_duplicates().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(values['CSENDERENDPOINTID'])\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.where(_encoder.classes_ == None)[0][0]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.classes_ = np.delete( _encoder.classes_,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(new_directory + column + '.npy', _encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders[column] = _encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_encoder.transform(['SLMP_PLUS_MS'])\n",
    "_encoder.transform([classes[9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column = 'CSENDERPROTOCOL'\n",
    "npy= share_directory + 'sla/' + version_sla + '/npy'\n",
    "_encoder = TolerantLabelEncoder(ignore_unknown=True)\n",
    "_encoder.classes_ = np.load(npy + '/' + column + '.npy')\n",
    "_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.where(_encoder.classes_ == None)[0][0]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.inverse_transform([5634])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoder.transform(['fff8bb00-a213-11e9-a189-ddafac1b495c'])\n",
    "#_encoder.transform(['VAT.UK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sort(_encoder.classes_)\n",
    "#_encoder.transform(_encoder.classes_)\n",
    "_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(['AS2', 'AS4', 'HTTP', 'MAIL', 'N/A', 'OFTP2', 'PEPPOL', 'QUEUE',\n",
    "       'REST', 'SFTP', 'SLMP', 'SLMPPOLL', 'SLMP_PLUS_MS', 'unknown'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
