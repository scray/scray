{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f463c4e3-b2c2-4a85-8604-51941e7908ed",
   "metadata": {},
   "source": [
    "# tool_update_encoded_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365c10db-5e6f-4cdb-9cca-8bdcce377ba2",
   "metadata": {},
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62276ad9-2063-4f6f-959b-519b94ce2817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dfBasics\n",
    "import common\n",
    "import encoder\n",
    "#import pfAdapt\n",
    "#import charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849076f-6695-4acc-b229-bd0787708cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e21252-87af-4f36-b046-f4bc77b7cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkSession = dfBasics.getSparkSession()\n",
    "#df = sparkSession.read.parquet('hdfs://172.30.17.145:8020/user/admin/sla/v00001/v00002/encoded/all/*/*').dropDuplicates() \n",
    "df3  = sparkSession.read.parquet('hdfs://172.30.17.145:8020/sla_sql_data/*/*').dropDuplicates() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde5b78f-499f-4ca9-b6ab-7cdad95b2634",
   "metadata": {},
   "source": [
    "## load encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3725aa-3292-4f54-9d40-0b4f5c3c684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dfBasics\n",
    "import pandas as pd\n",
    "\n",
    "version_sla = 'v00002'\n",
    "version     = version_sla + '/v00000'\n",
    "\n",
    "home_directory  =  '/home/jovyan/work/'\n",
    "share_directory =  '/home/jovyan/work/share/'\n",
    "#share_directory =  '/home/jovyan/share/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e2600-a036-433c-af38-a00b2620d19a",
   "metadata": {},
   "source": [
    "### init encoders (run only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c24828f-1851-48e0-ba21-a9fb2ba8f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - run this paragraph only once !\n",
    "# - if you get an 'allow_pickle' error you need Kernel/restart kernel\n",
    "\n",
    "import encoder\n",
    "import numpy as np\n",
    "\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "# restore np.load for future normal usage\n",
    "#np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad1cfa-8cf2-40c4-928e-47de6d0eb43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoders(columns):\n",
    "    npy= share_directory + 'sla/' + version_sla + '/npy'\n",
    "    encoders = {}\n",
    "    for column in columns:\n",
    "        _encoder = encoder.TolerantLabelEncoder(ignore_unknown=True)\n",
    "        #_encoder = TolerantLabelEncoder(ignore_unknown=True)\n",
    "        _encoder.classes_ = np.load(npy + '/' + column + '.npy')\n",
    "        encoders[column] = _encoder\n",
    "    return encoders    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248b464c-184b-41c0-8ae5-a1de5bb90c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['CSTATUS', 'CSERVICE', 'CSENDERENDPOINTID', 'CSENDERPROTOCOL','CRECEIVERPROTOCOL', 'CRECEIVERENDPOINTID']\n",
    "encoders = get_encoders(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5db5fe6-be00-43ce-b7e2-52f1d1332cdb",
   "metadata": {},
   "source": [
    "## functions_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9070e4cd-ce36-4aed-9c13-5f8bb8506672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import encoder\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "036feef6-d769-45f2-b727-79477d95d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import time\n",
    "import datetime as dt\n",
    "import calendar\n",
    "import pytz\n",
    "de = pytz.timezone('Europe/Berlin')\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# long timestamp\n",
    "def date(x):\n",
    "    return  dt.datetime.fromtimestamp(float(x) / 1e3, tz=de)\n",
    "\n",
    "udf_add_year = udf(lambda z: date(z).date().year, IntegerType())\n",
    "udf_add_month = udf(lambda z: date(z).date().month, IntegerType())\n",
    "udf_add_week = udf(lambda z: date(z).date().isocalendar()[1], IntegerType())\n",
    "udf_add_day = udf(lambda z: date(z).date().day, IntegerType())\n",
    "udf_add_hour = udf(lambda z: date(z).time().hour, IntegerType())\n",
    "udf_add_minute = udf(lambda z: date(z).time().minute, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "837e48db-331b-4d60-84e6-5005d430a44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport datetime\\ndatetime.date(2010, 6, 16).isocalendar()[1]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import datetime\n",
    "datetime.date(2010, 6, 16).isocalendar()[1]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce55254-fa9c-4cfc-a8d9-9c9076d806f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_error(columns):\n",
    "    status = columns[0]\n",
    "    service = columns[1]\n",
    "    error=int(not( ( check_transformed(status,'CSTATUS','PENDING') & check_transformed(service,'CSERVICE','InvoicePortal')  ) | \\\n",
    "        (check_transformed(status,'CSTATUS','PENDING') & check_transformed(service,'CSERVICE','IDS')  ) | \\\n",
    "        check_transformed(status,'CSTATUS','SUCCESS') | \\\n",
    "        check_transformed(status,'CSTATUS','SUCCESS_DOWNLOADED') | check_transformed(status,'CSTATUS','SUCCESS_POLLQUEUE')  ))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e7b7a-2c62-407b-8d9e-f84166fd5f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "udf_add_error = udf(lambda y,z: calc_error((y,z)), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5964e1db-862b-44f1-9a55-12dd1a223cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def transform(value):\n",
    "    if value == None:\n",
    "        value = 'None'\n",
    "    result = int( _encoder.transform_version([value])[0])\n",
    "    return result\n",
    "    \n",
    "#udf_transform = udf(lambda z: transform(z), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e809619a-0a80-4311-b6b0-692cc886ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_columns_spark(dataframe=None,columns=None, encoders=None):\n",
    "    for column in columns:\n",
    "        global _encoder\n",
    "        _encoder = encoders[column]\n",
    "        #print(column,_encoder)\n",
    "        udf_transform = udf(lambda z: transform(z), StringType())\n",
    "        dataframe=dataframe.withColumn(column, udf_transform(col(column)).cast(\"Integer\"))\n",
    "        #print(dataframe.head())\n",
    "    return dataframe\n",
    "\n",
    "def cast_spark_columns(dataframe=None,columns=[],type=\"int\" ):\n",
    "    for column in columns:\n",
    "        dataframe = dataframe.withColumn(column, col(column).cast(type))\n",
    "    return dataframe    \n",
    "\n",
    "def process(dataframe=None, encoders=None, columns=None, sender=None):\n",
    "    df3 = encode_columns_spark(dataframe=dataframe,columns=columns, encoders=encoders)\n",
    "    df3 = df3.withColumn(\"year\", udf_add_year(df3.CSTARTTIME)).withColumn(\"month\", udf_add_month(df3.CSTARTTIME)).withColumn(\"week\", udf_add_week(df3.CSTARTTIME)).withColumn(\"day\", udf_add_day(df3.CSTARTTIME)).withColumn(\"hour\", udf_add_hour(df3.CSTARTTIME)).withColumn(\"minute\", udf_add_minute(df3.CSTARTTIME)) \n",
    "    df3=cast_spark_columns(dataframe=df3, columns=['CSTARTTIME', 'CENDTIME','CINBOUNDSIZE','CSLATAT','CMESSAGETAT2','CSLADELIVERYTIME'], type='long')\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d96231-049e-4650-8650-0074e1a231d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_encoder.transform_version(['None'])\n",
    "#_encoder.transform([None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4b2d7-f021-486d-b7c9-f9e2d90c01b1",
   "metadata": {},
   "source": [
    "## update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32d746-017b-4141-97b6-6b3b475bea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_update(year,month,df,encoders=None, columns=None):\n",
    "    df2 = df.where(f.col(\"year\").isin([year])).where(f.col(\"month\").isin([month]))\n",
    "    df3 = process(dataframe=df2, encoders=encoders, columns=columns)\n",
    "    df4 = df3.withColumn(\"error\", udf_add_error(f.col(\"CSTATUS\"), f.col(\"CSERVICE\")).cast(IntegerType()))\n",
    "    df4.write.mode('overwrite').parquet('/home/jovyan/work/output/v00003_v00000/sla_enc_v00003_v00000_' + str(year) + '_' + str(month) + '.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a547a1-8c62-4a78-bc54-acc4f5250498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir /home/jovyan/work/output/v00003_v00000\n",
    "#!ls /home/jovyan/work/output/v00003_v00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f36b8-94fe-4783-bfb1-4f736b2e356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ear = 2019\n",
    "month = 10\n",
    "df2 = df.where(f.col(\"year\").isin([year])).where(f.col(\"month\").isin([month]))\n",
    "    \n",
    "df3 = df2.where((f.col('CSTATUS')==-1) | (f.col('CSERVICE')==-1) | (f.col('CSENDERENDPOINTID')==-1) | (f.col('CSENDERPROTOCOL')==-1)| (f.col('CRECEIVERPROTOCOL')==-1) | (f.col('CRECEIVERENDPOINTID')==-1))\n",
    "ids = np.array(df3.select('CGLOBALMESSAGEID').drop_duplicates().collect())     \n",
    "ids = [i[0] for i in ids.tolist()]\n",
    "not_ids = np.array(df2.select('CGLOBALMESSAGEID').filter(df2.CGLOBALMESSAGEID.isin(ids) == False).drop_duplicates().collect())  \n",
    "not_ids = [i[0] for i in not_ids.tolist()]\n",
    "\n",
    "df_update_1 = df_org.where(f.col(\"CGLOBALMESSAGEID\").isin(ids))\n",
    "df_update_2 = process(dataframe=df_update_1, encoders=encoders, columns=columns)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b9d54-4973-4d9b-8a95-659fce1c2a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_df3 = encode_columns_spark(dataframe=df_update_1,columns=columns, encoders=encoders)\n",
    "#_df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e92a8e-169f-491d-a18f-29932815ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_update_2 = process(dataframe=df_update_1, encoders=encoders, columns=columns)\n",
    "#df_update_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70e725-12b1-4aa9-a400-e404d55cacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#date(z).date().year\n",
    "#df2 = df.where(f.col(\"CSTARTTIME\").isin([year]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf2647-22b1-4365-85ae-5b34a490b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df3.withColumn(\"year\", udf_add_year(df3.CSTARTTIME)).withColumn(\"month\", udf_add_month(df3.CSTARTTIME)).withColumn(\"week\", udf_add_week(df3.CSTARTTIME)).withColumn(\"day\", udf_add_day(df3.CSTARTTIME)).withColumn(\"hour\", udf_add_hour(df3.CSTARTTIME)).withColumn(\"minute\", udf_add_minute(df3.CSTARTTIME)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a51852-8207-4a0c-b579-6fd5e062e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode('overwrite').parquet('/home/jovyan/work/output/v00003_v00000.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ad2f5-174d-4adf-b334-0a1d70802c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
