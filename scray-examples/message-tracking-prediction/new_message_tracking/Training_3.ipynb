{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adf3669c-02b3-4020-b38b-e3b70f7a105a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30bc93c-6f33-4ff1-8ee1-4f3c4a7cce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import DataCollector as collector\n",
    "dc = collector.DataCollector()\n",
    "import ModelTrainer as trainer\n",
    "mt = trainer.ModelTrainer()\n",
    "import FeaturePreparer as preparer\n",
    "fp = preparer.FeaturePreparer()\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc287a15-4f49-4571-be61-e05551c78495",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7abd0935-2de9-4ad0-8ab8-bd3efd0dfe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc._init_()\n",
    "data = dc.loadData()\n",
    "#result = data.select(F.avg('CMESSAGETAT2'))\n",
    "#result.show()\n",
    "#print(data.count())\n",
    "spark = dc.getSparkSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f816caa1-7a86-4f22-b612-d8fde14c7ea2",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb9e71c7-fd7e-490c-99db-e8018d8c8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dc.getStatistics(data)\n",
    "#data = dc.negativeValues(data)\n",
    "#data = dc.zeroValues(data)\n",
    "#data = dc.duplicatedValues(data)\n",
    "#data = dc.missingValues(data)\n",
    "#data = dc.outlierValues(data)\n",
    "#dc.eda(data)\n",
    "#dc.pca(data)\n",
    "\n",
    "#data.write.mode('overwrite').parquet(dc.all_path_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ad14c-55a0-4601-91b2-355c6805f3b9",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e02e95-d8db-4f21-873f-8d4548c98d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645091\n",
      "30320\n"
     ]
    }
   ],
   "source": [
    "#data = fp.prepare_data_for_training_3(data)\n",
    "#data = dc.getSparkSession().read.parquet(dc.sample_path_cleaned)\n",
    "data = fp.prepare_data_for_training_3(data)\n",
    "print(data.filter(data.traffic_light == 0).count())\n",
    "print(data.filter(data.traffic_light == 1).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bafc3e5-8a6d-44c9-9050-9b0f76490d7f",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f35d65f8-fd79-455b-ade9-a592c5b73a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Explanations"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_training_3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspark\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/new_message_tracking/ModelTrainer.py:333\u001b[0m, in \u001b[0;36mModelTrainer.perform_training_3\u001b[0;34m(self, data, spark)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m#self.printmd('## Metrics')                                                 #\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m#self.e3_get_metrics(prediction)                                            #\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprintmd(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m## Explanations\u001b[39m\u001b[38;5;124m'\u001b[39m)                                            \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43me3_model_explanations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m                               \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprintmd(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m## Confusion Matrix\u001b[39m\u001b[38;5;124m'\u001b[39m)                                        \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me3_get_confusion_matrix(prediction)\n",
      "File \u001b[0;32m~/work/new_message_tracking/ModelTrainer.py:392\u001b[0m, in \u001b[0;36mModelTrainer.e3_model_explanations\u001b[0;34m(self, model, test_data)\u001b[0m\n\u001b[1;32m    390\u001b[0m boost \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_booster()\n\u001b[1;32m    391\u001b[0m test \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 392\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoDF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m test_pd \u001b[38;5;241m=\u001b[39mtest\u001b[38;5;241m.\u001b[39mtoPandas()\n\u001b[1;32m    396\u001b[0m shap\u001b[38;5;241m.\u001b[39minitjs()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:115\u001b[0m, in \u001b[0;36m_monkey_patch_RDD.<locals>.toDF\u001b[0;34m(self, schema, sampleRatio)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;129m@no_type_check\u001b[39m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtoDF\u001b[39m(\u001b[38;5;28mself\u001b[39m, schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sampleRatio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    Converts current :class:`RDD` into a :class:`DataFrame`\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    +---+\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampleRatio\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:1276\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[1;32m   1273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(SparkSession, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreateDataFrame(  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m   1274\u001b[0m         data, schema, samplingRatio, verifySchema\n\u001b[1;32m   1275\u001b[0m     )\n\u001b[0;32m-> 1276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1278\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:1316\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, RDD):\n\u001b[0;32m-> 1316\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_createFromRDD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1318\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_createFromLocal(\u001b[38;5;28mmap\u001b[39m(prepare, data), schema)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:936\u001b[0m, in \u001b[0;36mSparkSession._createFromRDD\u001b[0;34m(self, rdd, schema, samplingRatio)\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    935\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(schema):\n\u001b[0;32m--> 936\u001b[0m             \u001b[43mstruct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    937\u001b[0m             struct\u001b[38;5;241m.\u001b[39mnames[i] \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, StructType):\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model = mt.perform_training_3(data, spark)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
